{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let first connect to the driver\n",
    "\n",
    "driver=webdriver.Edge(r\"msedgedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. \n",
    "You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 \n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening naukri.com page on automated Edge browser\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering designation, skill or companies(DSC) as required in the question\n",
    "# the 1st line will only select the DSC box and will not write anything in that\n",
    "DSC=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "\n",
    "\n",
    "#By this we can enter into the DSC box -> by send keys ---> Data Analyst\n",
    "\n",
    "DSC.send_keys(\"Data Analyst\")\n",
    "\n",
    "\n",
    "# this is done by Class method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering location as Bangalore as required in the question\n",
    "# the 1st line will only select the DSC box and will not write anything in that\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input\")\n",
    "\n",
    "#By this we can enter into the location box -> by send keys\n",
    "\n",
    "location.send_keys('Bangalore')\n",
    "\n",
    "# this is done by XPATH method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()\n",
    "\n",
    "# For clicking on click button we will do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from the given page\n",
    "\n",
    "title_tag=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tag[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "     \n",
    "\n",
    "# scraping job location from the given page\n",
    "\n",
    "location_tag=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tag[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "    \n",
    "# scraping company name from given page\n",
    "\n",
    "company_tag=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tag[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# scraping job experience from given page\n",
    "\n",
    "exp_tag=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in exp_tag[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print (len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB_TITLE</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>COMPANY_NAME</th>\n",
       "      <th>EXP_NEEDED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Old Madras Road)</td>\n",
       "      <td>KrazyBee</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Qualitest India Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Pune</td>\n",
       "      <td>Global Indian School Education Services</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Master Data Management Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Intern Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>FullStackTechies</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - Python/Artificial Intelligence</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>iMindYourBusiness</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>McAfee</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Ahmedabad</td>\n",
       "      <td>milestone internet marketing pvt ltd</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bayer</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       JOB_TITLE  \\\n",
       "0                            Senior Data Analyst   \n",
       "1                            Senior Data Analyst   \n",
       "2                               Sr. Data Analyst   \n",
       "3        Master Data Management Business Analyst   \n",
       "4                            Senior Data Analyst   \n",
       "5                            Intern Data Analyst   \n",
       "6  Data Analyst - Python/Artificial Intelligence   \n",
       "7                              Lead Data Analyst   \n",
       "8                                   Data Analyst   \n",
       "9                                   Data Analyst   \n",
       "\n",
       "                                            LOCATION  \\\n",
       "0               Bangalore/Bengaluru(Old Madras Road)   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                          Bangalore/Bengaluru, Pune   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                     Bangalore/Bengaluru, Ahmedabad   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                              COMPANY_NAME EXP_NEEDED  \n",
       "0                                 KrazyBee    3-6 Yrs  \n",
       "1          Qualitest India Private Limited    5-8 Yrs  \n",
       "2  Global Indian School Education Services   6-11 Yrs  \n",
       "3                                Accenture    6-8 Yrs  \n",
       "4                                    Optum    5-7 Yrs  \n",
       "5                         FullStackTechies    0-1 Yrs  \n",
       "6                        iMindYourBusiness    0-2 Yrs  \n",
       "7                                   McAfee    5-9 Yrs  \n",
       "8     milestone internet marketing pvt ltd    2-7 Yrs  \n",
       "9                                    Bayer    2-5 Yrs  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'JOB_TITLE':job_title,'LOCATION':job_location,'COMPANY_NAME':company_name,'EXP_NEEDED':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. \n",
    "You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering designation, skill or companies(DSC) as required in the question\n",
    "# the 1st line will only select the DSC box and will not write anything in that\n",
    "DSC=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "\n",
    "\n",
    "#By this we can enter into the DSC box -> by send keys ---> as Data Scientist\n",
    "\n",
    "DSC.send_keys(\"Data Scientist\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering location as Bangalore as required in the question\n",
    "# the 1st line will only select the DSC box and will not write anything in that\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input\")\n",
    "\n",
    "#By this we can enter into the location box -> by send keys\n",
    "\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()\n",
    "\n",
    "# For clicking on click button we will do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from the given page\n",
    "\n",
    "title_tag=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tag[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "     \n",
    "\n",
    "# scraping job location from the given page\n",
    "\n",
    "location_tag=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tag[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "    \n",
    "# scraping company name from given page\n",
    "\n",
    "company_tag=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tag[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print (len(job_title),len(job_location),len(company_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB_TITLE</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>COMPANY_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Manager - EmTech - Machine Learning - P&amp;T</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>PwC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data scientist _Tata Consultancy Services(Tcs)</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, Indore, New...</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Job||Job Opening For AI Technologist - Data Sc...</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tcs Hiring For Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai, Mumbai (All Areas)</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Urgent Job Opening For AI Practitioner - Data ...</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist Python</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad</td>\n",
       "      <td>Conduent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...</td>\n",
       "      <td>ZS Associates</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           JOB_TITLE  \\\n",
       "0   Senior Manager - EmTech - Machine Learning - P&T   \n",
       "1                   Analystics & Modeling Specialist   \n",
       "2     Data scientist _Tata Consultancy Services(Tcs)   \n",
       "3  Job||Job Opening For AI Technologist - Data Sc...   \n",
       "4  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "5                      Tcs Hiring For Data Scientist   \n",
       "6  Urgent Job Opening For AI Practitioner - Data ...   \n",
       "7                              Data Scientist Python   \n",
       "8                   Assistant Manager - Data Science   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                            LOCATION  \\\n",
       "0  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "2  Bangalore/Bengaluru, Kochi/Cochin, Indore, New...   \n",
       "3  Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...   \n",
       "4  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "5   Bangalore/Bengaluru, Chennai, Mumbai (All Areas)   \n",
       "6  Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...   \n",
       "7        Bangalore/Bengaluru, Hyderabad/Secunderabad   \n",
       "8                  Bangalore/Bengaluru, Mumbai, Pune   \n",
       "9  Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...   \n",
       "\n",
       "                                  COMPANY_NAME  \n",
       "0                                          PwC  \n",
       "1                                    Accenture  \n",
       "2              TATA CONSULTANCY SERVICES (TCS)  \n",
       "3                                        Wipro  \n",
       "4  NTT DATA Business Solutions Private Limited  \n",
       "5              TATA CONSULTANCY SERVICES (TCS)  \n",
       "6                                        Wipro  \n",
       "7                                     Conduent  \n",
       "8                                   CitiusTech  \n",
       "9                                ZS Associates  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'JOB_TITLE':job_title,'LOCATION':job_location,'COMPANY_NAME':company_name})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "\n",
    "*You have to use the location and salary filter.*\n",
    "\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "\n",
    "You have to scrape the job-title, job-location, company name, experience required. \n",
    "\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs*"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSC=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "DSC.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# salary filter for range of 3-6 lakhs\n",
    "sal_filt=driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[6]/div[2]/div[2]/label/p/span[1]\")\n",
    "\n",
    "\n",
    "\n",
    "sal_filt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# location filter for Delhi/NCR\n",
    "\n",
    "loc_filt=driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[2]/div[2]/div[2]/label/p/span[1]\")\n",
    "\n",
    "\n",
    "\n",
    "loc_filt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping filtered job title from the given page\n",
    "\n",
    "title_tag=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tag[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "     \n",
    "\n",
    "# scraping filtered job location from the given page\n",
    "\n",
    "location_tag=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tag[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "    \n",
    "# scraping filtered company name from given page\n",
    "\n",
    "company_tag=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tag[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# scraping job experience from given page\n",
    "\n",
    "exp_tag=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in exp_tag[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print (len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB_TITLE</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>COMPANY_NAME</th>\n",
       "      <th>EXPER_needed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job||Job Opening For AI Technologist - Data Sc...</td>\n",
       "      <td>New Delhi, Hyderabad/Secunderabad, Pune, Chenn...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Noida/Bangalore</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>EXL</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Predictive Analytics</td>\n",
       "      <td>Noida, Mumbai, Chandigarh, Hyderabad/Secundera...</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chat-bot Developer / Data Scientist</td>\n",
       "      <td>Mumbai, New Delhi, Bangalore/Bengaluru\\n(WFH d...</td>\n",
       "      <td>Big Seo Buzz</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist / Chat-bot Developer</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...</td>\n",
       "      <td>Big Seo Buzz</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>SECUREKLOUD TECHNOLOGIES</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Jaipur</td>\n",
       "      <td>Celebal Technologies</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           JOB_TITLE  \\\n",
       "0  Job||Job Opening For AI Technologist - Data Sc...   \n",
       "1                   Data Scientist - Noida/Bangalore   \n",
       "2                    DigitalBCG GAMMA Data Scientist   \n",
       "3              Data Scientist - Predictive Analytics   \n",
       "4                                     Data Scientist   \n",
       "5                Chat-bot Developer / Data Scientist   \n",
       "6                Data Scientist / Chat-bot Developer   \n",
       "7                  Data Scientist - Engine Algorithm   \n",
       "8         Data Scientist For Healthcare Product team   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                            LOCATION  \\\n",
       "0  New Delhi, Hyderabad/Secunderabad, Pune, Chenn...   \n",
       "1                         Noida, Bangalore/Bengaluru   \n",
       "2                     New Delhi, Bangalore/Bengaluru   \n",
       "3  Noida, Mumbai, Chandigarh, Hyderabad/Secundera...   \n",
       "4                                   Gurgaon/Gurugram   \n",
       "5  Mumbai, New Delhi, Bangalore/Bengaluru\\n(WFH d...   \n",
       "6  New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...   \n",
       "7  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "8          Delhi / NCR, Chennai, Bangalore/Bengaluru   \n",
       "9                    Noida, Gurgaon/Gurugram, Jaipur   \n",
       "\n",
       "               COMPANY_NAME EXPER_needed  \n",
       "0                     Wipro     5-10 Yrs  \n",
       "1                       EXL     5-10 Yrs  \n",
       "2   Boston Consulting Group      2-5 Yrs  \n",
       "3              Confidential      1-6 Yrs  \n",
       "4                     Optum      2-7 Yrs  \n",
       "5              Big Seo Buzz      2-7 Yrs  \n",
       "6              Big Seo Buzz      3-7 Yrs  \n",
       "7              Primo Hiring      1-3 Yrs  \n",
       "8  SECUREKLOUD TECHNOLOGIES      2-7 Yrs  \n",
       "9      Celebal Technologies      1-5 Yrs  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'JOB_TITLE':job_title,'LOCATION':job_location,'COMPANY_NAME':company_name,'EXPER_needed':experience_required})\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and \n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the \n",
    "required data as usual.\n",
    "\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then \n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking_cross_button\n",
    "crs_btn = driver.find_element(By.XPATH,\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "crs_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_box=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_box.send_keys(\"sunglassses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "product_desc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "                        # PAGE 1\n",
    "\n",
    "# scraping brand/product from the given page1\n",
    "\n",
    "brand_tag=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tag[0:40]:\n",
    "    product=i.text\n",
    "    brand.append(product)\n",
    "    \n",
    "# scraping price/cost from the given page1\n",
    "\n",
    "price_tag=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tag[0:40]:\n",
    "    cost=i.text\n",
    "    price.append(cost)\n",
    "    \n",
    "    \n",
    "# scraping discount from given page1\n",
    "\n",
    "discount_tag=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "for i in discount_tag[0:40]:\n",
    "    dis=i.text\n",
    "    discount.append(dis)\n",
    "    \n",
    "# scraping desciption from page 1\n",
    "\n",
    "desc_tag=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in desc_tag[0:40]:\n",
    "    des=i.text\n",
    "    product_desc.append(des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40 40\n"
     ]
    }
   ],
   "source": [
    "print (len(brand),len(price),len(discount),len(product_desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND_NAME</th>\n",
       "      <th>COST</th>\n",
       "      <th>DISCOUNT</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹799</td>\n",
       "      <td>20% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹224</td>\n",
       "      <td>85% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹252</td>\n",
       "      <td>90% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (52)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>₹200</td>\n",
       "      <td>84% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>₹283</td>\n",
       "      <td>78% off</td>\n",
       "      <td>UV Protection, Polarized Wayfarer Sunglasses (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>₹298</td>\n",
       "      <td>88% off</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>₹207</td>\n",
       "      <td>79% off</td>\n",
       "      <td>UV Protection Oval Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>₹264</td>\n",
       "      <td>89% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹323</td>\n",
       "      <td>87% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>₹267</td>\n",
       "      <td>73% off</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (53)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>₹195</td>\n",
       "      <td>88% off</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "      <td>Polarized, Riding Glasses Sports, Wrap-around ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>₹198</td>\n",
       "      <td>73% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>₹199</td>\n",
       "      <td>80% off</td>\n",
       "      <td>Riding Glasses, Night Vision Spectacle Sunglas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹221</td>\n",
       "      <td>86% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹1,039</td>\n",
       "      <td>20% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lee Topper</td>\n",
       "      <td>₹219</td>\n",
       "      <td>78% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>₹350</td>\n",
       "      <td>82% off</td>\n",
       "      <td>UV Protection, Mirrored Retro Square Sunglasse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Dannilo</td>\n",
       "      <td>₹170</td>\n",
       "      <td>78% off</td>\n",
       "      <td>Others Spectacle Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mi</td>\n",
       "      <td>₹799</td>\n",
       "      <td>33% off</td>\n",
       "      <td>Polarized Aviator Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹710</td>\n",
       "      <td>21% off</td>\n",
       "      <td>UV Protection Wrap-around Sunglasses (63)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>₹259</td>\n",
       "      <td>80% off</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Retro Squar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹719</td>\n",
       "      <td>20% off</td>\n",
       "      <td>UV Protection Shield Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>EYELLUSION</td>\n",
       "      <td>₹199</td>\n",
       "      <td>80% off</td>\n",
       "      <td>Riding Glasses, Riding Glasses, UV Protection ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>₹269</td>\n",
       "      <td>85% off</td>\n",
       "      <td>UV Protection, Mirrored Aviator Sunglasses (Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>₹288</td>\n",
       "      <td>80% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹749</td>\n",
       "      <td>62% off</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Rectangul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>₹325</td>\n",
       "      <td>53% off</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹719</td>\n",
       "      <td>20% off</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>₹189</td>\n",
       "      <td>85% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (55)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "      <td>UV Protection, Gradient Butterfly Sunglasses (62)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>IZAAN MART</td>\n",
       "      <td>₹290</td>\n",
       "      <td>85% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (55)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹759</td>\n",
       "      <td>15% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹203</td>\n",
       "      <td>87% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>₹299</td>\n",
       "      <td>50% off</td>\n",
       "      <td>Gradient Wayfarer Sunglasses (52)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Lee Topper</td>\n",
       "      <td>₹299</td>\n",
       "      <td>88% off</td>\n",
       "      <td>Riding Glasses Wrap-around Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           BRAND_NAME    COST DISCOUNT  \\\n",
       "0            Fastrack    ₹799  20% off   \n",
       "1            Fastrack    ₹639  20% off   \n",
       "2              PIRASO    ₹224  85% off   \n",
       "3              PIRASO    ₹252  90% off   \n",
       "4                SRPM    ₹200  84% off   \n",
       "5              SUNBEE    ₹283  78% off   \n",
       "6           Elligator    ₹298  88% off   \n",
       "7           New Specs    ₹207  79% off   \n",
       "8            Fastrack    ₹639  20% off   \n",
       "9           New Specs    ₹264  89% off   \n",
       "10             PIRASO    ₹323  87% off   \n",
       "11         PHENOMENAL    ₹267  73% off   \n",
       "12  SHAAH COLLECTIONS    ₹195  88% off   \n",
       "13     ROZZETTA CRAFT    ₹499  75% off   \n",
       "14              NuVew    ₹198  73% off   \n",
       "15         LIZA ANGEL    ₹199  80% off   \n",
       "16             PIRASO    ₹221  86% off   \n",
       "17     ROZZETTA CRAFT    ₹499  77% off   \n",
       "18           Fastrack  ₹1,039  20% off   \n",
       "19         Lee Topper    ₹219  78% off   \n",
       "20         PHENOMENAL    ₹350  82% off   \n",
       "21            Dannilo    ₹170  78% off   \n",
       "22                 Mi    ₹799  33% off   \n",
       "23           Fastrack    ₹710  21% off   \n",
       "24             SUNBEE    ₹259  80% off   \n",
       "25           Fastrack    ₹719  20% off   \n",
       "26         EYELLUSION    ₹199  80% off   \n",
       "27     kingsunglasses    ₹269  85% off   \n",
       "28       Silver Kartz    ₹288  80% off   \n",
       "29      VINCENT CHASE    ₹749  62% off   \n",
       "30          Rich Club    ₹325  53% off   \n",
       "31           Fastrack    ₹719  20% off   \n",
       "32     kingsunglasses    ₹189  85% off   \n",
       "33          ROYAL SON    ₹664  66% off   \n",
       "34         IZAAN MART    ₹290  85% off   \n",
       "35           Fastrack    ₹759  15% off   \n",
       "36     ROZZETTA CRAFT    ₹399  80% off   \n",
       "37             PIRASO    ₹203  87% off   \n",
       "38          Rich Club    ₹299  50% off   \n",
       "39         Lee Topper    ₹299  88% off   \n",
       "\n",
       "                                          DESCRIPTION  \n",
       "0       UV Protection Wayfarer Sunglasses (Free Size)  \n",
       "1    UV Protection Rectangular Sunglasses (Free Size)  \n",
       "2               UV Protection Aviator Sunglasses (54)  \n",
       "3           UV Protection Rectangular Sunglasses (52)  \n",
       "4              UV Protection Wayfarer Sunglasses (50)  \n",
       "5   UV Protection, Polarized Wayfarer Sunglasses (...  \n",
       "6                 UV Protection Round Sunglasses (54)  \n",
       "7           UV Protection Oval Sunglasses (Free Size)  \n",
       "8        UV Protection Aviator Sunglasses (Free Size)  \n",
       "9    UV Protection Rectangular Sunglasses (Free Size)  \n",
       "10              UV Protection Aviator Sunglasses (58)  \n",
       "11         UV Protection Retro Square Sunglasses (53)  \n",
       "12  UV Protection, Polarized, Mirrored Rectangular...  \n",
       "13  Polarized, Riding Glasses Sports, Wrap-around ...  \n",
       "14              UV Protection Aviator Sunglasses (57)  \n",
       "15  Riding Glasses, Night Vision Spectacle Sunglas...  \n",
       "16              UV Protection Aviator Sunglasses (54)  \n",
       "17  UV Protection Retro Square Sunglasses (Free Size)  \n",
       "18              UV Protection Aviator Sunglasses (58)  \n",
       "19   UV Protection Rectangular Sunglasses (Free Size)  \n",
       "20  UV Protection, Mirrored Retro Square Sunglasse...  \n",
       "21            Others Spectacle Sunglasses (Free Size)  \n",
       "22           Polarized Aviator Sunglasses (Free Size)  \n",
       "23          UV Protection Wrap-around Sunglasses (63)  \n",
       "24  UV Protection, Polarized, Mirrored Retro Squar...  \n",
       "25        UV Protection Shield Sunglasses (Free Size)  \n",
       "26  Riding Glasses, Riding Glasses, UV Protection ...  \n",
       "27  UV Protection, Mirrored Aviator Sunglasses (Fr...  \n",
       "28      UV Protection Wayfarer Sunglasses (Free Size)  \n",
       "29  by Lenskart Polarized, UV Protection Rectangul...  \n",
       "30         UV Protection Retro Square Sunglasses (54)  \n",
       "31  Gradient, UV Protection Wayfarer Sunglasses (F...  \n",
       "32          UV Protection Rectangular Sunglasses (55)  \n",
       "33  UV Protection, Gradient Butterfly Sunglasses (62)  \n",
       "34          UV Protection Rectangular Sunglasses (55)  \n",
       "35      UV Protection Wayfarer Sunglasses (Free Size)  \n",
       "36  UV Protection, Gradient Rectangular Sunglasses...  \n",
       "37             UV Protection Wayfarer Sunglasses (32)  \n",
       "38                  Gradient Wayfarer Sunglasses (52)  \n",
       "39  Riding Glasses Wrap-around Sunglasses (Free Size)  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'BRAND_NAME':brand,'COST':price,'DISCOUNT':discount,'DESCRIPTION':product_desc})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "                        # PAGE 2\n",
    "\n",
    "# scraping brand/product from the given page2\n",
    "\n",
    "brand_tag=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tag[0:40]:\n",
    "    product=i.text\n",
    "    brand.append(product)\n",
    "    \n",
    "# scraping price/cost from the given page2\n",
    "\n",
    "price_tag=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tag[0:40]:\n",
    "    cost=i.text\n",
    "    price.append(cost)\n",
    "    \n",
    "    \n",
    "# scraping discount from given page2\n",
    "\n",
    "discount_tag=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "for i in discount_tag[0:40]:\n",
    "    dis=i.text\n",
    "    discount.append(dis)\n",
    "    \n",
    "desc_tag=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in desc_tag[0:40]:\n",
    "    des=i.text\n",
    "    product_desc.append(des)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 80 80 80\n"
     ]
    }
   ],
   "source": [
    "print (len(brand),len(price),len(discount),len(product_desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND_NAME</th>\n",
       "      <th>COST</th>\n",
       "      <th>DISCOUNT</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹799</td>\n",
       "      <td>20% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹224</td>\n",
       "      <td>85% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹252</td>\n",
       "      <td>90% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (52)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>₹200</td>\n",
       "      <td>84% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹759</td>\n",
       "      <td>15% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹203</td>\n",
       "      <td>87% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>₹299</td>\n",
       "      <td>50% off</td>\n",
       "      <td>Gradient Wayfarer Sunglasses (52)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Lee Topper</td>\n",
       "      <td>₹299</td>\n",
       "      <td>88% off</td>\n",
       "      <td>Riding Glasses Wrap-around Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BRAND_NAME  COST DISCOUNT  \\\n",
       "0         Fastrack  ₹799  20% off   \n",
       "1         Fastrack  ₹639  20% off   \n",
       "2           PIRASO  ₹224  85% off   \n",
       "3           PIRASO  ₹252  90% off   \n",
       "4             SRPM  ₹200  84% off   \n",
       "..             ...   ...      ...   \n",
       "75        Fastrack  ₹759  15% off   \n",
       "76  ROZZETTA CRAFT  ₹399  80% off   \n",
       "77          PIRASO  ₹203  87% off   \n",
       "78       Rich Club  ₹299  50% off   \n",
       "79      Lee Topper  ₹299  88% off   \n",
       "\n",
       "                                          DESCRIPTION  \n",
       "0       UV Protection Wayfarer Sunglasses (Free Size)  \n",
       "1    UV Protection Rectangular Sunglasses (Free Size)  \n",
       "2               UV Protection Aviator Sunglasses (54)  \n",
       "3           UV Protection Rectangular Sunglasses (52)  \n",
       "4              UV Protection Wayfarer Sunglasses (50)  \n",
       "..                                                ...  \n",
       "75      UV Protection Wayfarer Sunglasses (Free Size)  \n",
       "76  UV Protection, Gradient Rectangular Sunglasses...  \n",
       "77             UV Protection Wayfarer Sunglasses (32)  \n",
       "78                  Gradient Wayfarer Sunglasses (52)  \n",
       "79  Riding Glasses Wrap-around Sunglasses (Free Size)  \n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'BRAND_NAME':brand,'COST':price,'DISCOUNT':discount,'DESCRIPTION':product_desc})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "                        # PAGE 3\n",
    "\n",
    "# scraping brand/product from the given page3\n",
    "\n",
    "brand_tag=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tag[0:20]:\n",
    "    product=i.text\n",
    "    brand.append(product)\n",
    "    \n",
    "# scraping price/cost from the given page3\n",
    "\n",
    "price_tag=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tag[0:20]:\n",
    "    cost=i.text\n",
    "    price.append(cost)\n",
    "    \n",
    "    \n",
    "# scraping discount from given page3\n",
    "\n",
    "discount_tag=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "for i in discount_tag[0:20]:\n",
    "    dis=i.text\n",
    "    discount.append(dis)\n",
    "    \n",
    "desc_tag=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in desc_tag[0:20]:\n",
    "    des=i.text\n",
    "    product_desc.append(des)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print (len(brand),len(price),len(discount),len(product_desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND_NAME</th>\n",
       "      <th>COST</th>\n",
       "      <th>DISCOUNT</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹799</td>\n",
       "      <td>20% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹224</td>\n",
       "      <td>85% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹252</td>\n",
       "      <td>90% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (52)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>₹200</td>\n",
       "      <td>84% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>₹199</td>\n",
       "      <td>80% off</td>\n",
       "      <td>Riding Glasses, Night Vision Spectacle Sunglas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹221</td>\n",
       "      <td>86% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹1,039</td>\n",
       "      <td>20% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Lee Topper</td>\n",
       "      <td>₹219</td>\n",
       "      <td>78% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BRAND_NAME    COST DISCOUNT  \\\n",
       "0         Fastrack    ₹799  20% off   \n",
       "1         Fastrack    ₹639  20% off   \n",
       "2           PIRASO    ₹224  85% off   \n",
       "3           PIRASO    ₹252  90% off   \n",
       "4             SRPM    ₹200  84% off   \n",
       "..             ...     ...      ...   \n",
       "95      LIZA ANGEL    ₹199  80% off   \n",
       "96          PIRASO    ₹221  86% off   \n",
       "97  ROZZETTA CRAFT    ₹499  77% off   \n",
       "98        Fastrack  ₹1,039  20% off   \n",
       "99      Lee Topper    ₹219  78% off   \n",
       "\n",
       "                                          DESCRIPTION  \n",
       "0       UV Protection Wayfarer Sunglasses (Free Size)  \n",
       "1    UV Protection Rectangular Sunglasses (Free Size)  \n",
       "2               UV Protection Aviator Sunglasses (54)  \n",
       "3           UV Protection Rectangular Sunglasses (52)  \n",
       "4              UV Protection Wayfarer Sunglasses (50)  \n",
       "..                                                ...  \n",
       "95  Riding Glasses, Night Vision Spectacle Sunglas...  \n",
       "96              UV Protection Aviator Sunglasses (54)  \n",
       "97  UV Protection Retro Square Sunglasses (Free Size)  \n",
       "98              UV Protection Aviator Sunglasses (58)  \n",
       "99   UV Protection Rectangular Sunglasses (Free Size)  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'BRAND_NAME':brand,'COST':price,'DISCOUNT':discount,'DESCRIPTION':product_desc})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.flipkart.com/\n",
    "2. Enter “iphone 11” in “Search” field . \n",
    "3. Then click the search button\n",
    "\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/p/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART&q=iphone+11&store=tyy%2F4io&srno=s_1_2&otracker=search&otracker1=search&fm=organic&iid=79634d54-fe2f-4b48-8096-8c7d00ed789b.MOBFWQ6BXGJCEYNY.SEARCH&ppt=hp&ppn=homepage&ssid=4aqld4pxvk0000001660886113454&qH=f6cdfdaa9f3c23f3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on all reviews\n",
    "al_rev_btn = driver.find_element(By.XPATH,\"//div[@class='_3UAT2v _16PBlm']\")\n",
    "al_rev_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "irating = []\n",
    "short_sum = []\n",
    "full_description = []\n",
    "\n",
    "\n",
    "for page in range(0,11):\n",
    "    \n",
    "    #rating\n",
    "    rat_tag = driver.find_elements(By.XPATH,\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\")\n",
    "    for i in rat_tag:\n",
    "        irating.append(i.text)\n",
    "        \n",
    "    #review summary\n",
    "    shrt_sum = driver.find_elements(By.XPATH,\"//p[@class = '_2-N8zT']\")\n",
    "    for i in shrt_sum:\n",
    "        short_sum.append(i.text)\n",
    "\n",
    "    #full description\n",
    "    full_descr = driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']/div/div\")\n",
    "    for i in full_descr:\n",
    "        full_description.append(i.text)\n",
    "        \n",
    "        \n",
    "    next_page=driver.find_elements(By.XPATH,\"//a[@class='_1LKTO3']\")\n",
    "    for i in next_page:\n",
    "        if i.text == 'NEXT':\n",
    "            driver.get(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping RATING from the given page\n",
    "\n",
    "rating_tag=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in rating_tag[0:10]:\n",
    "    rating=i.text\n",
    "    Rating.append(rating)\n",
    "    \n",
    "# scraping Review_summary from the given page\n",
    "\n",
    "RS_tag=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "for i in RS_tag[0:10]:\n",
    "    rev=i.text\n",
    "    Review_summary.append(rev)\n",
    "    \n",
    "    \n",
    "# scraping full review from given page\n",
    "\n",
    "FR_tag=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "for i in FR_tag[0:10]:\n",
    "    frev=i.text\n",
    "    Full_review.append(frev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratings</th>\n",
       "      <th>short_review</th>\n",
       "      <th>full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Don’t expect much from front camera… especiall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>This is my first ever iPhone.\\nAnd I truly don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Absolutely powerful gadget. Loved it’s look! S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Flipkart honoured on time delivery, I have use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Overall it’s good.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ratings           short_review  \\\n",
       "0        5         Simply awesome   \n",
       "1        5       Perfect product!   \n",
       "2        5    Best in the market!   \n",
       "3        5      Worth every penny   \n",
       "4        5     Highly recommended   \n",
       "..     ...                    ...   \n",
       "95       5    Best in the market!   \n",
       "96       5                 Super!   \n",
       "97       5  Mind-blowing purchase   \n",
       "98       5  Mind-blowing purchase   \n",
       "99       5         Simply awesome   \n",
       "\n",
       "                                          full_review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   What a camera .....just awesome ..you can feel...  \n",
       "..                                                ...  \n",
       "95  Don’t expect much from front camera… especiall...  \n",
       "96  This is my first ever iPhone.\\nAnd I truly don...  \n",
       "97  Absolutely powerful gadget. Loved it’s look! S...  \n",
       "98  Flipkart honoured on time delivery, I have use...  \n",
       "99                                 Overall it’s good.  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(len(irating),len(short_sum),len(full_description))\n",
    "\n",
    "sol_data = pd.DataFrame({\n",
    "    'ratings':irating[0:100],\n",
    "    'short_review':short_sum[0:100],\n",
    "    'full_review': full_description[0:100]\n",
    "})\n",
    "\n",
    "sol_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_data.to_csv('iphone_review.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching sneakers\n",
    "search_bar = driver.find_element(By.XPATH,\"//input[@class='_3704LK']\")\n",
    "search_bar.send_keys('sneakers')\n",
    "\n",
    "#clicking_search button\n",
    "search_button = driver.find_element(By.XPATH,\"//button[@class='L0Z3Pu']\")\n",
    "search_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoe_brand=[]\n",
    "shoe_description=[]\n",
    "shoe_price=[]\n",
    "shoe_discount=[]\n",
    "\n",
    "#scrapping the required details\n",
    "for page in range(0,4):      #for loop for scrapping 3 page\n",
    "    brands=driver.find_elements(By.CLASS_NAME,'_2WkVRV')    #scraping brands name by class name='_2B_pmu'\n",
    "    for i in brands:\n",
    "        shoe_brand.append(i.text)    #appending the text in Brand list\n",
    "    desc=driver.find_elements(By.CLASS_NAME,'IRpwTa')    #scraping description by class name = '_2mylT6'\n",
    "    for i in desc:\n",
    "        shoe_description.append(i.get_attribute('title'))   #appending the description in list\n",
    "    prices=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")  # scraping the price from the xpath\n",
    "    for i in prices[:40]:\n",
    "        shoe_price.append(i.text)\n",
    "    disc=driver.find_elements(By.XPATH,\"//div[@class='_3Ay6Sb']\")# scraping the discount from the xpath\n",
    "    for i in disc:\n",
    "        shoe_discount.append(i.text)\n",
    "        \n",
    "    next_page=driver.find_elements(By.XPATH,\"//a[@class='_1LKTO3']\")\n",
    "    for i in next_page:\n",
    "        if i.text == 'NEXT':\n",
    "            driver.get(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>DISCOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Mesh | Ultralightweight | Comfortable | Breath...</td>\n",
       "      <td>₹374</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>₹544</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹373</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers White Shoes For Girls And Wome...</td>\n",
       "      <td>₹549</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>69% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>AMICO</td>\n",
       "      <td>Designer Printed Casual Sneakers Shoes Sneaker...</td>\n",
       "      <td>₹424</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Feet Runner</td>\n",
       "      <td>Stylish Casual Sneakers for Women Sneakers For...</td>\n",
       "      <td>₹659</td>\n",
       "      <td>56% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           BRAND                                        DESCRIPTION PRICE  \\\n",
       "0           aadi  Mesh | Ultralightweight | Comfortable | Breath...  ₹374   \n",
       "1         Chevit  Super Stylish & Trendy Combo Pack of 02 Pairs ...  ₹544   \n",
       "2         Labbin                                   Sneakers For Men  ₹499   \n",
       "3      Deals4you                                 Sneakers For Women  ₹373   \n",
       "4         Layasa                                   Sneakers For Men  ₹399   \n",
       "..           ...                                                ...   ...   \n",
       "95  Robbie jones  Casual Sneakers White Shoes For Girls And Wome...  ₹549   \n",
       "96        Shozie                                 Sneakers For Women  ₹399   \n",
       "97        BRUTON      Modern Trendy Sneakers Shoes Sneakers For Men  ₹399   \n",
       "98         AMICO  Designer Printed Casual Sneakers Shoes Sneaker...  ₹424   \n",
       "99   Feet Runner  Stylish Casual Sneakers for Women Sneakers For...  ₹659   \n",
       "\n",
       "   DISCOUNT  \n",
       "0   81% off  \n",
       "1   71% off  \n",
       "2   50% off  \n",
       "3   62% off  \n",
       "4   60% off  \n",
       "..      ...  \n",
       "95  45% off  \n",
       "96  60% off  \n",
       "97  69% off  \n",
       "98  57% off  \n",
       "99  56% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoe_data = pd.DataFrame({})\n",
    "shoe_data['BRAND'] = shoe_brand[0:100]\n",
    "shoe_data['DESCRIPTION'] = shoe_description[0:100]\n",
    "shoe_data['PRICE'] = shoe_price[0:100]\n",
    "shoe_data['DISCOUNT'] = shoe_discount[0:100]\n",
    "\n",
    "shoe_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7: Go to the link - https://www.myntra.com/shoes\n",
    "\n",
    "Set second Price filter and Color filter to “Black”, as shown in the below image.\n",
    "\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe \n",
    "description, price of the shoe as shown in the below image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.myntra.com/shoes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on the price range of Rs. 6627 to Rs. 13085\n",
    "\n",
    "price = driver.find_element(By.XPATH,\"//ul[@class='price-list']/li[2]\")\n",
    "price.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on color filter and changing it to black\n",
    "color = driver.find_element(By.XPATH,\"//li[@class='colour-listItem']\")\n",
    "color.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_shoe = []\n",
    "price_shoe = []\n",
    "descr_shoe = []\n",
    "s_desc_shoe = []\n",
    "\n",
    "\n",
    "for page in range(0,2): \n",
    "    \n",
    "    \n",
    "    shoe_brnd = driver.find_elements(By.XPATH,\"//div[@class='product-productMetaInfo']/h3\")\n",
    "    for i in shoe_brnd:\n",
    "        brand_shoe.append(i.text)\n",
    "            \n",
    "    shoe_price = driver.find_elements(By.XPATH,\"//div[@class='product-price']\")\n",
    "    for i in shoe_price:\n",
    "        price_shoe.append(i.text)\n",
    "        \n",
    "    shrt_des = driver.find_elements(By.XPATH,\"//div[@class='product-productMetaInfo']/h4\")\n",
    "    for i in shrt_des:\n",
    "        s_desc_shoe.append(i.text)\n",
    "        \n",
    "    for j in range(0,len(s_desc_shoe),2):\n",
    "        descr_shoe.append(s_desc_shoe[j])\n",
    "        \n",
    "    nxt_button=driver.find_element(By.XPATH,'//li[@class=\"pagination-next\"]')\n",
    "    #for scrapping the datas from next pages.\n",
    "    if nxt_button.text=='next':\n",
    "            nxt_button.click()\n",
    "            time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 7465Rs. 8295(10% OFF)</td>\n",
       "      <td>Men ZOOM WINFLO8 Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Rs. 7199Rs. 8999(20% OFF)</td>\n",
       "      <td>Men Max Cushioning Running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 11895Rs. 13995(15% OFF)</td>\n",
       "      <td>Men React Infinity 3 Running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 10795</td>\n",
       "      <td>Men Colourblocked Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Rs. 7199Rs. 8999(20% OFF)</td>\n",
       "      <td>Men Max Cushioning Running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Rs. 11049Rs. 12999(15% OFF)</td>\n",
       "      <td>Men Ozrah Leather Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Rs. 10199Rs. 11999(15% OFF)</td>\n",
       "      <td>Men Adizero Adios 7 Running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Rs. 9749Rs. 12999(25% OFF)</td>\n",
       "      <td>Women Eternity NITRO Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Rs. 7199Rs. 11999(40% OFF)</td>\n",
       "      <td>Men KING Top Football Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Rs. 12999</td>\n",
       "      <td>Men Dropset Training Shoes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                NAME                        PRICE  \\\n",
       "0               Nike    Rs. 7465Rs. 8295(10% OFF)   \n",
       "1           Skechers    Rs. 7199Rs. 8999(20% OFF)   \n",
       "2               Nike  Rs. 11895Rs. 13995(15% OFF)   \n",
       "3               Nike                    Rs. 10795   \n",
       "4           Skechers    Rs. 7199Rs. 8999(20% OFF)   \n",
       "..               ...                          ...   \n",
       "95  ADIDAS Originals  Rs. 11049Rs. 12999(15% OFF)   \n",
       "96            ADIDAS  Rs. 10199Rs. 11999(15% OFF)   \n",
       "97              Puma   Rs. 9749Rs. 12999(25% OFF)   \n",
       "98              Puma   Rs. 7199Rs. 11999(40% OFF)   \n",
       "99            ADIDAS                    Rs. 12999   \n",
       "\n",
       "                       DESCRIPTION  \n",
       "0   Men ZOOM WINFLO8 Running Shoes  \n",
       "1       Men Max Cushioning Running  \n",
       "2     Men React Infinity 3 Running  \n",
       "3       Men Colourblocked Sneakers  \n",
       "4       Men Max Cushioning Running  \n",
       "..                             ...  \n",
       "95      Men Ozrah Leather Sneakers  \n",
       "96     Men Adizero Adios 7 Running  \n",
       "97      Women Eternity NITRO Shoes  \n",
       "98     Men KING Top Football Shoes  \n",
       "99      Men Dropset Training Shoes  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil_data = pd.DataFrame({\n",
    "    'NAME':brand_shoe[0:100],\n",
    "    'PRICE':price_shoe[0:100],\n",
    "    'DESCRIPTION':descr_shoe[0:100]\n",
    "})\n",
    "\n",
    "fil_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” as shown in the below image\n",
    "\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.amazon.in/')\n",
    "#enter laptop\n",
    "driver.find_element(By.XPATH,\"//input[@id='twotabsearchtextbox']\").send_keys('Laptop')\n",
    "#enter search button\n",
    "driver.find_element(By.ID,\"nav-search-submit-text\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select filter of CPU type to intel core i7\n",
    "\n",
    "cpu_filt=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[4]/li[11]/span/a/span\")\n",
    "\n",
    "\n",
    "\n",
    "cpu_filt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Ratings=[]\n",
    "Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping filtered title from the given page\n",
    "\n",
    "title_tag=driver.find_elements(By.XPATH,'//div[@class=\"a-section a-spacing-none puis-padding-right-small s-title-instructions-style\"]')\n",
    "for i in title_tag[0:10]:\n",
    "    ti=i.text\n",
    "    Title.append(ti)\n",
    "\n",
    "     \n",
    "\n",
    "# scraping filtered Rating from the given page\n",
    "\n",
    "Rating_tag=driver.find_elements(By.XPATH,'//div[@class=\"a-row a-size-small\"]')\n",
    "for i in Rating_tag[0:10]:\n",
    "    rat=i.text\n",
    "    Ratings.append(rat)\n",
    "    \n",
    "    \n",
    "# scraping filtered Price from given page\n",
    "\n",
    "price_tag=driver.find_elements(By.XPATH,'//span[@class=\"a-price\"]')\n",
    "for i in price_tag[0:10]:\n",
    "    price=i.text\n",
    "    Price.append(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>RATING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 39...</td>\n",
       "      <td>₹79,490</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...</td>\n",
       "      <td>₹82,200</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>₹57,990</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS VivoBook K15 OLED (2021), 15.6-inch FHD O...</td>\n",
       "      <td>₹82,990</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo ThinkPad E14 Intel Core i7 11th Gen 14-...</td>\n",
       "      <td>₹94,990</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS TUF Gaming F15 (2022), 15.6-inch (39.62 c...</td>\n",
       "      <td>₹1,09,990</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS Zenbook 14 OLED (2022), 14\" (35.56 cms) 2...</td>\n",
       "      <td>₹1,04,990</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Samsung Galaxy Book2 360 Intel 12th Gen i7 Evo...</td>\n",
       "      <td>₹97,990</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>₹89,990</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS TUF Gaming F15 (2022), 15.6\" (39.62 cms) ...</td>\n",
       "      <td>₹1,09,990</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             PRODUCT      PRICE RATING\n",
       "0  Samsung Galaxy Book2 Intel 12th Gen core i7 39...    ₹79,490     26\n",
       "1  Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...    ₹82,200     23\n",
       "2  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...    ₹57,990     26\n",
       "3  ASUS VivoBook K15 OLED (2021), 15.6-inch FHD O...    ₹82,990     11\n",
       "4  Lenovo ThinkPad E14 Intel Core i7 11th Gen 14-...    ₹94,990      3\n",
       "5  ASUS TUF Gaming F15 (2022), 15.6-inch (39.62 c...  ₹1,09,990     24\n",
       "6  ASUS Zenbook 14 OLED (2022), 14\" (35.56 cms) 2...  ₹1,04,990     16\n",
       "7  Samsung Galaxy Book2 360 Intel 12th Gen i7 Evo...    ₹97,990     17\n",
       "8  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...    ₹89,990     19\n",
       "9  ASUS TUF Gaming F15 (2022), 15.6\" (39.62 cms) ...  ₹1,09,990      6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIL_DATA = pd.DataFrame({\n",
    "    'PRODUCT':Title[0:10],\n",
    "    'PRICE':Price[0:10],\n",
    "    'RATING':Ratings[0:10]\n",
    "})\n",
    "\n",
    "FIL_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9 : Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida \n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company. \n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button.\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "“Noida” and select location “Noida”.\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(' https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs=driver.find_element(By.XPATH,\"/html/body/div[1]/nav[2]/div/ul/li[5]/a\")\n",
    "jobs.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'//span[@class=\"ctas-btn-medium\"]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]/p')\n",
    "location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on Noida as a filter\n",
    "\n",
    "fil_noida=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[5]/div/label')\n",
    "fil_noida.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "company_name=[]\n",
    "posted=[]\n",
    "rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tag=driver.find_elements(By.XPATH,'//a[@class=\"title noclick\"]')\n",
    "for i in title_tag[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "\n",
    "\n",
    "CN_tag=driver.find_elements(By.XPATH,'//div[@class=\"company-info\"]')\n",
    "for i in CN_tag[0:10]:\n",
    "    cn=i.text\n",
    "    company_name.append(cn)\n",
    "    \n",
    "\n",
    "    \n",
    "pos_tag=driver.find_elements(By.XPATH,'//span[@class=\"body-small-l\"]')\n",
    "for i in pos_tag[0:10]:\n",
    "    po=i.text\n",
    "    posted.append(po)\n",
    "    \n",
    "\n",
    "rat_tag=driver.find_elements(By.XPATH,'//span[@class=\"body-small\"]')\n",
    "for i in rat_tag[0:10]:\n",
    "    rat=i.text\n",
    "    rating.append(rat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print (len(job_title),len(company_name),len(posted),len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hiring Data Scientist #productbasecompany #CBRE',\n",
       " 'Hiring For Genpact-Data Scientist- Forecasting-Immediate Joiners only',\n",
       " 'Genpact - Data Scientist - Forecasting/Python/R (6-10 yrs)',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB_TITLE</th>\n",
       "      <th>COMPANY_NAME</th>\n",
       "      <th>POSTED_DATE</th>\n",
       "      <th>RATING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hiring For Data Analyst / Data Scientist</td>\n",
       "      <td>PEPSICO GLOBAL BUSINESS SERVICES INDIA LLP\\n ·...</td>\n",
       "      <td>2d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring Data Scientist #productbasecompany #CBRE</td>\n",
       "      <td>PEPSICO GLOBAL BUSINESS SERVICES INDIA LLP\\n4....</td>\n",
       "      <td>via naukri.com</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist Lead_Tata Consultancy Services(...</td>\n",
       "      <td>CBRE South Asia Pvt Ltd\\n4.3\\n(2.3k Reviews)</td>\n",
       "      <td>8d ago</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>via naukri.com</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           JOB_TITLE  \\\n",
       "0           Hiring For Data Analyst / Data Scientist   \n",
       "1    Hiring Data Scientist #productbasecompany #CBRE   \n",
       "2  Data Scientist Lead_Tata Consultancy Services(...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "5                                                      \n",
       "6                                                      \n",
       "7                                                      \n",
       "8                                                      \n",
       "9                                                      \n",
       "\n",
       "                                        COMPANY_NAME     POSTED_DATE RATING  \n",
       "0  PEPSICO GLOBAL BUSINESS SERVICES INDIA LLP\\n ·...          2d ago    4.1  \n",
       "1  PEPSICO GLOBAL BUSINESS SERVICES INDIA LLP\\n4....  via naukri.com    4.3  \n",
       "2       CBRE South Asia Pvt Ltd\\n4.3\\n(2.3k Reviews)          8d ago         \n",
       "3                                                     via naukri.com         \n",
       "4                                                                            \n",
       "5                                                                            \n",
       "6                                                                            \n",
       "7                                                                            \n",
       "8                                                                            \n",
       "9                                                                            "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'JOB_TITLE':job_title,'COMPANY_NAME':company_name,'POSTED_DATE':posted,'RATING':rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =-----------------=-------------------------=-----------------------=----------------------=--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary. \n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and \n",
    "then click on “Data Scientist”.\n",
    "\n",
    "You have to scrape the data ticked in the above image.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average \n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(' https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Select=driver.find_element(By.XPATH,\"/html/body/div[1]/nav[2]/div/ul/li[3]/a\")\n",
    "Select.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsalary=driver.find_element(By.XPATH,\"/html/body/div[1]/nav[2]/div/ul/li[3]/div/ul/li[1]/div\")\n",
    "bsalary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.XPATH,\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience_Required=[]\n",
    "company_name=[]\n",
    "Total_Salary=[]\n",
    "Average=[]\n",
    "Minimum=[]\n",
    "Maximum=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_tags=driver.find_elements(By.CLASS_NAME,'sbold-list-header')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    Experience_Required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Experience_Required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_tags=driver.find_elements(By.XPATH,'//div[@class=\"company-info\"]//a')\n",
    "for i in company_tags[0:10]:\n",
    "  company=i.text\n",
    "  company_name.append(company)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tags=driver.find_elements(By.XPATH,'//p[@class=\"averageCtc\"]')\n",
    "for i in avg_tags[0:10]:\n",
    "  avg=i.text\n",
    "  Average.append(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_tags=driver.find_elements(By.XPATH,'//span[@class=\"datapoints\"]')\n",
    "for i in TS_tags[0:10]:\n",
    "  TS=i.text\n",
    "  Total_Salary.append(TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Total_Salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_tags=driver.find_elements(By.XPATH,'//div[@class=\"value body-medium\"]')\n",
    "for i in min_tags[0:10]:\n",
    "  min=i.text\n",
    "  Minimum.append(min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tags=driver.find_elements(By.XPATH,'//div[@class=\"value body-medium\"]')\n",
    "for i in max_tags[0:10]:\n",
    "  max=i.text\n",
    "  Maximum.append(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(Experience_Required),len(company_name),len(Total_Salary),len(Minimum),len(Maximum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Total Salary Record</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google\\nSoftware Engineer Salary</td>\n",
       "      <td>(based on 51 salaries)</td>\n",
       "      <td>₹ 11.7L</td>\n",
       "      <td>₹ 11.7L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft Corporation\\nSoftware Engineer Salary</td>\n",
       "      <td>(based on 334 salaries)</td>\n",
       "      <td>₹ 97.0L</td>\n",
       "      <td>₹ 97.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Goldman Sachs\\nSoftware Engineer Salary</td>\n",
       "      <td>(based on 36 salaries)</td>\n",
       "      <td>₹ 13.0L</td>\n",
       "      <td>₹ 13.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon\\nSoftware Engineer Salary</td>\n",
       "      <td>(based on 133 salaries)</td>\n",
       "      <td>₹ 50.0L</td>\n",
       "      <td>₹ 50.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Servicenow Software Development India\\nSoftwar...</td>\n",
       "      <td>(based on 71 salaries)</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tekion\\nSoftware Engineer Salary</td>\n",
       "      <td>(based on 41 salaries)</td>\n",
       "      <td>₹ 34.0L</td>\n",
       "      <td>₹ 34.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Walmart\\nSoftware Engineer Salary</td>\n",
       "      <td>(based on 105 salaries)</td>\n",
       "      <td>₹ 8.7L</td>\n",
       "      <td>₹ 8.7L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PayPal\\nSoftware Engineer Salary</td>\n",
       "      <td>(based on 29 salaries)</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Arista Networks\\nSoftware Engineer Salary</td>\n",
       "      <td>(based on 56 salaries)</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arcesium\\nSoftware Engineer Salary</td>\n",
       "      <td>(based on 68 salaries)</td>\n",
       "      <td>₹ 30.0L</td>\n",
       "      <td>₹ 30.0L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company Name      Total Salary Record  \\\n",
       "0                   Google\\nSoftware Engineer Salary   (based on 51 salaries)   \n",
       "1    Microsoft Corporation\\nSoftware Engineer Salary  (based on 334 salaries)   \n",
       "2            Goldman Sachs\\nSoftware Engineer Salary   (based on 36 salaries)   \n",
       "3                   Amazon\\nSoftware Engineer Salary  (based on 133 salaries)   \n",
       "4  Servicenow Software Development India\\nSoftwar...   (based on 71 salaries)   \n",
       "5                   Tekion\\nSoftware Engineer Salary   (based on 41 salaries)   \n",
       "6                  Walmart\\nSoftware Engineer Salary  (based on 105 salaries)   \n",
       "7                   PayPal\\nSoftware Engineer Salary   (based on 29 salaries)   \n",
       "8          Arista Networks\\nSoftware Engineer Salary   (based on 56 salaries)   \n",
       "9                 Arcesium\\nSoftware Engineer Salary   (based on 68 salaries)   \n",
       "\n",
       "  Maximum Salary Minimum Salary  \n",
       "0        ₹ 11.7L        ₹ 11.7L  \n",
       "1        ₹ 97.0L        ₹ 97.0L  \n",
       "2        ₹ 13.0L        ₹ 13.0L  \n",
       "3        ₹ 50.0L        ₹ 50.0L  \n",
       "4        ₹ 12.0L        ₹ 12.0L  \n",
       "5        ₹ 34.0L        ₹ 34.0L  \n",
       "6         ₹ 8.7L         ₹ 8.7L  \n",
       "7        ₹ 45.0L        ₹ 45.0L  \n",
       "8        ₹ 14.0L        ₹ 14.0L  \n",
       "9        ₹ 30.0L        ₹ 30.0L  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Company Name':company_name,\"Total Salary Record\":Total_Salary,\"Maximum Salary\":Maximum, \"Minimum Salary\":Minimum})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
