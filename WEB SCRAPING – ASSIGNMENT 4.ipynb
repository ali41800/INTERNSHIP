{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39a0757c",
   "metadata": {},
   "source": [
    "# - - - -                  --   --  WEB SCRAPING – ASSIGNMENT 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f5e1f5",
   "metadata": {},
   "source": [
    "## Q1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "\n",
    "**Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos**\n",
    "\n",
    "**You need to find following details:**\n",
    "\n",
    "**A) Rank**\n",
    "\n",
    "**B) Name**\n",
    "\n",
    "**C) Artist**\n",
    "\n",
    "**D) Upload date**\n",
    "\n",
    "**E) Views**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a50e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "import time\n",
    "from bs4 import BeautifulSoup \n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320f2f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "997405b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let first connect to the driver\n",
    "\n",
    "driver=webdriver.Edge(r\"msedgedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cfddc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "400b2441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list for storing data after scraping\n",
    "\n",
    "Rank = []\n",
    "Name = []\n",
    "Artist = []\n",
    "Upload_date = []\n",
    "Views = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2857af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Rank of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07e47b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping rank\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\"):\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5187848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping Artist\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//*[@id=\"mw-content-text\"]/div[1]/table[2]/tbody/tr/td[3]'):\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e33c1a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping upload Date\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,' //table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[5]'):\n",
    "        Upload_date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Upload_date.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b29346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Views of videos\n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\"):\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Views.append(\"_\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f5df859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame from scraped data\n",
    "YT_list = pd.DataFrame({})\n",
    "YT_list['Rank']=Rank\n",
    "YT_list['Name']=Name\n",
    "YT_list['Artist']=Artist\n",
    "YT_list['Upload Date']=Upload_date\n",
    "YT_list['Views']=Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe94c242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[3]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>11.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[6]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[12]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[13]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"[15]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Bath Song\"[20]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[21]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>4.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Uptown Funk\"[22]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[23]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Gangnam Style\"[24]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[29]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Wheels on the Bus\"[30]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[31]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[32]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[33]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[34]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Sorry\"[35]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Axel F\"[36]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Thinking Out Loud\"[37]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[38]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Dark Horse\"[39]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Faded\"[40]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Girls Like You\"[41]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[42]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Bailando\"[43]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Lean On\"[44]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Perfect\"[45]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[46]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Shake It Off\"[47]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[3]   \n",
       "1    2.                                   \"Despacito\"[6]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[12]   \n",
       "3    4.                               \"Shape of You\"[13]   \n",
       "4    5.                              \"See You Again\"[15]   \n",
       "5    6.                                  \"Bath Song\"[20]   \n",
       "6    7.                \"Phonics Song with Two Words\"[21]   \n",
       "7    8.                                \"Uptown Funk\"[22]   \n",
       "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[23]   \n",
       "9   10.                              \"Gangnam Style\"[24]   \n",
       "10  11.   \"Masha and the Bear – Recipe for Disaster\"[29]   \n",
       "11  12.                          \"Wheels on the Bus\"[30]   \n",
       "12  13.                             \"Dame Tu Cosita\"[31]   \n",
       "13  14.                                      \"Sugar\"[32]   \n",
       "14  15.                                       \"Roar\"[33]   \n",
       "15  16.                             \"Counting Stars\"[34]   \n",
       "16  17.                                      \"Sorry\"[35]   \n",
       "17  18.                                     \"Axel F\"[36]   \n",
       "18  18.                          \"Thinking Out Loud\"[37]   \n",
       "19  20.                        \"Baa Baa Black Sheep\"[38]   \n",
       "20  21.                                 \"Dark Horse\"[39]   \n",
       "21  22.                                      \"Faded\"[40]   \n",
       "22  23.                             \"Girls Like You\"[41]   \n",
       "23  24.                                 \"Let Her Go\"[42]   \n",
       "24  25.                                   \"Bailando\"[43]   \n",
       "25  26.                                    \"Lean On\"[44]   \n",
       "26  27.                                    \"Perfect\"[45]   \n",
       "27  28.           \"Waka Waka (This Time for Africa)\"[46]   \n",
       "28  29.                               \"Shake It Off\"[47]   \n",
       "29  30.          \"Humpty the train on a fruits ride\"[48]   \n",
       "\n",
       "                                           Artist        Upload Date  Views  \n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  11.24  \n",
       "1                                      Luis Fonsi   January 12, 2017   7.96  \n",
       "2                                     LooLoo Kids    October 8, 2016   6.44  \n",
       "3                                      Ed Sheeran   January 30, 2017   5.80  \n",
       "4                                     Wiz Khalifa      April 6, 2015   5.62  \n",
       "5                      Cocomelon – Nursery Rhymes        May 2, 2018   5.59  \n",
       "6                                       ChuChu TV      March 6, 2014   4.85  \n",
       "7                                     Mark Ronson  November 19, 2014   4.68  \n",
       "8                                     Miroshka TV  February 27, 2018   4.61  \n",
       "9                                             Psy      July 15, 2012   4.53  \n",
       "10                                     Get Movies   January 31, 2012   4.51  \n",
       "11                     Cocomelon – Nursery Rhymes       May 24, 2018   4.31  \n",
       "12                                      El Chombo      April 5, 2018   4.05  \n",
       "13                                       Maroon 5   January 14, 2015   3.75  \n",
       "14                                     Katy Perry  September 5, 2013   3.64  \n",
       "15                                    OneRepublic       May 31, 2013   3.63  \n",
       "16                                  Justin Bieber   October 22, 2015   3.58  \n",
       "17                                     Crazy Frog      June 16, 2009   3.49  \n",
       "18                                     Ed Sheeran    October 7, 2014   3.49  \n",
       "19                     Cocomelon – Nursery Rhymes      June 25, 2018   3.35  \n",
       "20                                     Katy Perry  February 20, 2014   3.34  \n",
       "21                                    Alan Walker   December 3, 2015   3.33  \n",
       "22                                       Maroon 5       May 31, 2018   3.33  \n",
       "23                                      Passenger      July 25, 2012   3.29  \n",
       "24                               Enrique Iglesias     April 11, 2014   3.26  \n",
       "25                                    Major Lazer     March 22, 2015   3.25  \n",
       "26                                     Ed Sheeran   November 9, 2017   3.24  \n",
       "27                                        Shakira       June 4, 2010   3.23  \n",
       "28                                   Taylor Swift    August 18, 2014   3.20  \n",
       "29  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   3.14  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3fb2508",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9783ffa1",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b213056",
   "metadata": {},
   "source": [
    "## Q2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "**Url = https://www.bcci.tv/.**\n",
    "\n",
    "**You need to find following details:**\n",
    "\n",
    "**A) Match title (I.e. 1st ODI)**\n",
    "\n",
    "**B) Series**\n",
    "\n",
    "**C) Place**\n",
    "\n",
    "**D) Date**\n",
    "\n",
    "**E) Time**\n",
    "\n",
    "\n",
    "**Note: - From bcci.tv home page you have reach to the international fixture page through code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30580a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let first connect to the driver\n",
    "\n",
    "driver=webdriver.Edge(r\"msedgedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e03199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=('https://www.bcci.tv/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2684b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clickin on International tab\n",
    "International = driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a') # click button\n",
    "International.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05bdc5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Empty List\n",
    "Name=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "416f1667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping Name\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]'):\n",
    "        Name.append(i.text.replace('-',\"\"))\n",
    "except NoSuchElementException:\n",
    "    Name.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cdaa8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping Series\n",
    "try:\n",
    "    \n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]'):\n",
    "        Series.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Series.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ea12b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping Place\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]'):\n",
    "        Place.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Place.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d46eaaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping Date\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//h5[@class=\"ng-binding\"]'):\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90be8e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping Time\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//h5[@class=\"text-right ng-binding\"]'):\n",
    "        Time.append(i.text.replace('IST',\"\"))\n",
    "except NoSuchElementException:\n",
    "    Time.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0e49e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA WOMEN TOUR OF ENGLAND T20 SERIES 2022</td>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>County Ground,</td>\n",
       "      <td>13 SEP 2022</td>\n",
       "      <td>10:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA WOMEN TOUR OF ENGLAND T20 SERIES 2022</td>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>County Ground,</td>\n",
       "      <td>15 SEP 2022</td>\n",
       "      <td>11:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022</td>\n",
       "      <td>1st ODI</td>\n",
       "      <td>County Ground,</td>\n",
       "      <td>18 SEP 2022</td>\n",
       "      <td>3:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>1st T20I</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium,</td>\n",
       "      <td>20 SEP 2022</td>\n",
       "      <td>7:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022</td>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>St Lawrence Ground,</td>\n",
       "      <td>21 SEP 2022</td>\n",
       "      <td>5:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>Vidarbha Cricket Association Stadium,</td>\n",
       "      <td>23 SEP 2022</td>\n",
       "      <td>7:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022</td>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>Lord's Cricket Ground,</td>\n",
       "      <td>24 SEP 2022</td>\n",
       "      <td>3:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>Rajiv Gandhi International Stadium,</td>\n",
       "      <td>25 SEP 2022</td>\n",
       "      <td>7:30 PM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Title       Name  \\\n",
       "0  INDIA WOMEN TOUR OF ENGLAND T20 SERIES 2022  2nd T20I    \n",
       "1  INDIA WOMEN TOUR OF ENGLAND T20 SERIES 2022  3rd T20I    \n",
       "2  INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022   1st ODI    \n",
       "3      AUSTRALIA TOUR OF INDIA T20 SERIES 2022  1st T20I    \n",
       "4  INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022   2nd ODI    \n",
       "5      AUSTRALIA TOUR OF INDIA T20 SERIES 2022  2nd T20I    \n",
       "6  INDIA WOMEN TOUR OF ENGLAND ODI SERIES 2022   3rd ODI    \n",
       "7      AUSTRALIA TOUR OF INDIA T20 SERIES 2022  3rd T20I    \n",
       "\n",
       "                                           Place         Date       Time  \n",
       "0                                 County Ground,  13 SEP 2022  10:30 PM   \n",
       "1                                 County Ground,  15 SEP 2022  11:00 PM   \n",
       "2                                 County Ground,  18 SEP 2022   3:30 PM   \n",
       "3  Punjab Cricket Association IS Bindra Stadium,  20 SEP 2022   7:30 PM   \n",
       "4                            St Lawrence Ground,  21 SEP 2022   5:30 PM   \n",
       "5          Vidarbha Cricket Association Stadium,  23 SEP 2022   7:30 PM   \n",
       "6                         Lord's Cricket Ground,  24 SEP 2022   3:30 PM   \n",
       "7            Rajiv Gandhi International Stadium,  25 SEP 2022   7:30 PM   "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "\n",
    "BCCI=pd.DataFrame({})\n",
    "BCCI['Title']=Series\n",
    "BCCI['Name']=Name\n",
    "BCCI['Place']=Place\n",
    "BCCI['Date']=Date\n",
    "BCCI['Time']=Time\n",
    "BCCI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eaf09038",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1d6cf0",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb0db68",
   "metadata": {},
   "source": [
    "## Q3. Scrape the details of selenium exception from guru99.com.\n",
    "**Url = https://www.guru99.com/ You need to find following details:**\n",
    "\n",
    "**A) Name**\n",
    "\n",
    "**B) Description**\n",
    "\n",
    "**Note: - From guru99 home page you have to reach to selenium exception handling page through code.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d51d6135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let first connect to the driver\n",
    "\n",
    "driver=webdriver.Edge(r\"msedgedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c37d7b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.guru99.com/\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c06ffbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click Selenium Button\n",
    "Selenium = driver.find_element(By.XPATH,'//div[@class = \"wp-block-kadence-column inner-column-2 kadence-column_f38d98-3a\"]') # click button\n",
    "try:\n",
    "    Selenium.click()\n",
    "except ElementNotInteractableException:#handling element not clickable exception\n",
    "    driver.get(Selenium.get_attribute('href'))\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ef5a86f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click selenium exception handling  Button\n",
    "exception_handling = driver.find_element(By.XPATH,\"//a[@title='Selenium Exception Handling (Common Exceptions List)']\")\n",
    "try:\n",
    "    exception_handling.click()\n",
    "except ElementNotInteractableException:  #if the above code doesn't work/is not clickable then, the below code will handle it\n",
    "    driver.get(exception_handling.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "42650fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "description=[]\n",
    "#Scrapping Name\n",
    "for i in driver.find_elements(By.XPATH,'//table[@class=\"table table-striped\"]/tbody/tr/td[1]'):\n",
    "    name.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//table[@class=\"table table-striped\"]/tbody/tr/td[2]'):\n",
    "    description.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ad140765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exception name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Exception name, Description]\n",
       "Index: []"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selenium_Exception=pd.DataFrame()\n",
    "Selenium_Exception['Exception name']=name\n",
    "Selenium_Exception['Description']=description\n",
    "Selenium_Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e394cd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2ec4c",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe09ae4",
   "metadata": {},
   "source": [
    "# Q4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "\n",
    "Url = http://statisticstimes.com/ You have to find following details:\n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) State\n",
    "\n",
    "C) GSDP(18-19)\n",
    "\n",
    "D) GSDP(17-18)\n",
    "\n",
    "E) Share(2017)\n",
    "\n",
    "F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9f7f29a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let first connect to the driver\n",
    "\n",
    "driver=webdriver.Edge(r\"msedgedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "07432fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()\n",
    "driver.get('https://www.statisticstimes.com')\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b969b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click Economy\n",
    "Economy=driver.find_element(By.XPATH,\"//*[@id='top']/div[2]/div[2]/button\")\n",
    "Economy.click()\n",
    "\n",
    "#Click India\n",
    "India= driver.find_element(By.XPATH,\"//*[@id='top']/div[2]/div[2]/div/a[3]\")\n",
    "India.click()\n",
    "\n",
    "#Click on India GPD\n",
    "GDP=driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "GDP.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3bfe8a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "Rank=[]\n",
    "State=[]\n",
    "GSDP_at_current_price_18_19=[]\n",
    "GSDP_at_current_price_17_18=[]\n",
    "Share_17=[]\n",
    "GDP_billion=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c6d5d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping Rank\n",
    "rank= driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[1]\")\n",
    "for i in rank:\n",
    "    if i.text is None:\n",
    "        Rank.append('--')\n",
    "    else:\n",
    "        Rank.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8e0b7f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping State\n",
    "state= driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[2]\")\n",
    "for i in state:\n",
    "    if i.text is None:\n",
    "        State.append('--')\n",
    "    else:\n",
    "        State.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8ab84134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping GSDP_at_current_price_18_19\n",
    "gSDP_at_current_price_18_19= driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[3]\")\n",
    "for i in gSDP_at_current_price_18_19:\n",
    "    if i.text is None:\n",
    "        GSDP_at_current_price_18_19.append('--')\n",
    "    else:\n",
    "        GSDP_at_current_price_18_19.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "79d9cf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping GSDP_at_current_price_17_18\n",
    "gSDP_at_current_price_17_18= driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[4]\")\n",
    "for i in gSDP_at_current_price_17_18:\n",
    "    if i.text is None:\n",
    "        GSDP_at_current_price_17_18.append('--')\n",
    "    else:\n",
    "        GSDP_at_current_price_17_18.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "482b9ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping Share_17\n",
    "share_17= driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[5]\")\n",
    "for i in share_17:\n",
    "    if i.text is None:\n",
    "        Share_17.append('--')\n",
    "    else:\n",
    "        Share_17.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cd9c4d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping GDP_billion\n",
    "gDP_billion= driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[6]\")\n",
    "for i in gDP_billion:\n",
    "    if i.text is None:\n",
    "        GDP_billion.append('--')\n",
    "    else:\n",
    "        GDP_billion.append(i.text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5142a216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP_at_current_price_18_19</th>\n",
       "      <th>GSDP_at_current_price_17_18</th>\n",
       "      <th>Share_18_19</th>\n",
       "      <th>GDP_billion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank  State GSDP_at_current_price_18_19 GSDP_at_current_price_17_18  \\\n",
       "0    NaN    NaN                           -                   2,632,792   \n",
       "1    NaN    NaN                   1,845,853                   1,630,208   \n",
       "2    NaN    NaN                   1,687,818                   1,584,764   \n",
       "3    NaN    NaN                           -                   1,502,899   \n",
       "4    NaN    NaN                   1,631,977                   1,493,127   \n",
       "5    NaN    NaN                   1,253,832                   1,089,898   \n",
       "6    NaN    NaN                   1,020,989                     942,586   \n",
       "7    NaN    NaN                     972,782                     862,957   \n",
       "8    NaN    NaN                     969,604                     861,031   \n",
       "9    NaN    NaN                     906,672                     809,592   \n",
       "10   NaN    NaN                           -                     781,653   \n",
       "11   NaN    NaN                     856,112                     774,870   \n",
       "12   NaN    NaN                     831,610                     734,163   \n",
       "13   NaN    NaN                     611,804                     530,363   \n",
       "14   NaN    NaN                     574,760                     526,376   \n",
       "15   NaN    NaN                     521,275                     487,805   \n",
       "16   NaN    NaN                           -                     315,881   \n",
       "17   NaN    NaN                     329,180                     304,063   \n",
       "18   NaN    NaN                     328,598                     297,204   \n",
       "19   NaN    NaN                           -                     245,895   \n",
       "20   NaN    NaN                           -                     155,956   \n",
       "21   NaN    NaN                     165,472                     153,845   \n",
       "22   NaN    NaN                      80,449                      73,170   \n",
       "23   NaN    NaN                      55,984                      49,845   \n",
       "24   NaN    NaN                           -                      42,114   \n",
       "25   NaN    NaN                      38,253                      34,433   \n",
       "26   NaN    NaN                      36,572                      33,481   \n",
       "27   NaN    NaN                      32,496                      28,723   \n",
       "28   NaN    NaN                      31,790                      27,870   \n",
       "29   NaN    NaN                           -                      27,283   \n",
       "30   NaN    NaN                           -                      24,603   \n",
       "31   NaN    NaN                      26,503                      22,287   \n",
       "32   NaN    NaN                           -                           -   \n",
       "\n",
       "   Share_18_19 GDP_billion  \n",
       "0       13.94%     399.921  \n",
       "1        8.63%     247.629  \n",
       "2        8.39%     240.726  \n",
       "3        7.96%     228.290  \n",
       "4        7.91%     226.806  \n",
       "5        5.77%     165.556  \n",
       "6        4.99%     143.179  \n",
       "7        4.57%     131.083  \n",
       "8        4.56%     130.791  \n",
       "9        4.29%     122.977  \n",
       "10       4.14%     118.733  \n",
       "11       4.10%     117.703  \n",
       "12       3.89%     111.519  \n",
       "13       2.81%      80.562  \n",
       "14       2.79%      79.957  \n",
       "15       2.58%      74.098  \n",
       "16       1.67%      47.982  \n",
       "17       1.61%      46.187  \n",
       "18       1.57%      45.145  \n",
       "19       1.30%      37.351  \n",
       "20       0.83%      23.690  \n",
       "21       0.81%      23.369  \n",
       "22       0.39%      11.115  \n",
       "23       0.26%       7.571  \n",
       "24       0.22%       6.397  \n",
       "25       0.18%       5.230  \n",
       "26       0.18%       5.086  \n",
       "27       0.15%       4.363  \n",
       "28       0.15%       4.233  \n",
       "29       0.14%       4.144  \n",
       "30       0.13%       3.737  \n",
       "31       0.12%       3.385  \n",
       "32           -           -  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe\n",
    "GDP_India=pd.DataFrame({})\n",
    "GDP_India['Rank']=Rank\n",
    "GDP_India['State']=State\n",
    "GDP_India['GSDP_at_current_price_18_19']=GSDP_at_current_price_18_19\n",
    "GDP_India['GSDP_at_current_price_17_18']=GSDP_at_current_price_17_18\n",
    "GDP_India['Share_18_19']=Share_17\n",
    "GDP_India['GDP_billion']=GDP_billion\n",
    "GDP_India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "41ebedf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c11d2da",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04276903",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of trending repositories on Github.com.\n",
    "\n",
    "Url = https://github.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Repository title\n",
    "\n",
    "B) Repository description\n",
    "\n",
    "C) Contributors count\n",
    "\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "894bdba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let first connect to the driver\n",
    "\n",
    "driver=webdriver.Edge(r\"msedgedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "187c041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://github.com/trending')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ac7aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_box_url = driver.find_elements(By.XPATH,'//article/h1/a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "433218d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_urls = []\n",
    "for one_url in all_box_url:\n",
    "    all_urls.append(one_url.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5368bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty list for Scraping Data\n",
    "Title=[]\n",
    "Description=[]\n",
    "Count =[]\n",
    "Language =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33c46951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping repositories URL\n",
    "URL= []\n",
    "link=driver.find_elements(By.XPATH,'//h1[@class=\"h3 lh-condensed\"]/a')\n",
    "for i in link:\n",
    "    URL.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d820d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Repositority Title\n",
    "try:\n",
    "    title=driver.find_elements(By.XPATH,'//h1[@class=\"h3 lh-condensed\"]')\n",
    "    for i in title:\n",
    "        Title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Title.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b53b3259",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b91e392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [03:27<00:00,  8.31s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in tqdm(URL):\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    # Scraping Description\n",
    "    try:\n",
    "        description=driver.find_element(By.XPATH,'/html/body/div[4]/div/main/div[2]/div/div/div[2]/div[2]/div/div[1]/div/p')\n",
    "        Description.append(description.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('NA')\n",
    "    \n",
    "    # Scraping Contributor count\n",
    "    try:\n",
    "        count=driver.find_element(By.XPATH,\"//h2[@class='h4 mb-3']/a[contains(text(),'Contributors')]/span\")\n",
    "        Count.append(count.text)\n",
    "    except NoSuchElementException:\n",
    "        Count.append('NA')\n",
    "    \n",
    "    # Scraping Language\n",
    "    L =[]\n",
    "    try:\n",
    "        lang=driver.find_elements(By.XPATH,\"//li[@class='d-inline']//a//span[1]\")\n",
    "        if lang:\n",
    "            for j in lang:\n",
    "                L.append(j.text)\n",
    "        else:\n",
    "            L.append('NA')\n",
    "        Language.append(L)\n",
    "    except NoSuchElementException:\n",
    "        Language.append('NA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6633c3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mGitHub Trending Repository :\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contributors_count</th>\n",
       "      <th>Language_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>danielgindi / Charts</td>\n",
       "      <td>NA</td>\n",
       "      <td>150</td>\n",
       "      <td>[Swift, Objective-C]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>surrealdb / surrealdb</td>\n",
       "      <td>NA</td>\n",
       "      <td>11</td>\n",
       "      <td>[Rust]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheAlgorithms / Python</td>\n",
       "      <td>NA</td>\n",
       "      <td>831</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SerenityOS / ladybird</td>\n",
       "      <td>NA</td>\n",
       "      <td>16</td>\n",
       "      <td>[C++, CMake, Java]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>divamgupta / diffusionbee-stable-diffusion-ui</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>[Jupyter Notebook, Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>karpathy / nn-zero-to-hero</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>[Jupyter Notebook]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EbookFoundation / free-programming-books</td>\n",
       "      <td>NA</td>\n",
       "      <td>2,000</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>twitter / compose-rules</td>\n",
       "      <td>NA</td>\n",
       "      <td>8</td>\n",
       "      <td>[Kotlin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n8n-io / n8n</td>\n",
       "      <td>NA</td>\n",
       "      <td>301</td>\n",
       "      <td>[TypeScript, Vue, SCSS, JavaScript, HTML, Dock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InterviewReady / system-design-resources</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>moby / moby</td>\n",
       "      <td>NA</td>\n",
       "      <td>2,178</td>\n",
       "      <td>[Go, Shell, Dockerfile, PowerShell, Makefile, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Alamofire / Alamofire</td>\n",
       "      <td>NA</td>\n",
       "      <td>240</td>\n",
       "      <td>[Swift]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AykutSarac / jsoncrack.com</td>\n",
       "      <td>NA</td>\n",
       "      <td>14</td>\n",
       "      <td>[TypeScript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pocketbase / pocketbase</td>\n",
       "      <td>NA</td>\n",
       "      <td>14</td>\n",
       "      <td>[Go, Svelte, SCSS, JavaScript, HTML, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ascoders / weekly</td>\n",
       "      <td>NA</td>\n",
       "      <td>67</td>\n",
       "      <td>[JavaScript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>jellyfin / jellyfin</td>\n",
       "      <td>NA</td>\n",
       "      <td>758</td>\n",
       "      <td>[C#]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>apptension / developer-handbook</td>\n",
       "      <td>NA</td>\n",
       "      <td>4</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vasanthk / how-web-works</td>\n",
       "      <td>NA</td>\n",
       "      <td>8</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rust-lang / rust</td>\n",
       "      <td>NA</td>\n",
       "      <td>4,016</td>\n",
       "      <td>[Rust, JavaScript, HTML, Python, Makefile, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dotnet / core</td>\n",
       "      <td>NA</td>\n",
       "      <td>302</td>\n",
       "      <td>[PowerShell, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>microsoft / playwright</td>\n",
       "      <td>NA</td>\n",
       "      <td>294</td>\n",
       "      <td>[TypeScript, HTML, C++, CSS, JavaScript, Objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gothinkster / realworld</td>\n",
       "      <td>NA</td>\n",
       "      <td>73</td>\n",
       "      <td>[Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SerenityOS / serenity</td>\n",
       "      <td>NA</td>\n",
       "      <td>751</td>\n",
       "      <td>[C++, JavaScript, HTML, C, Shell, CMake]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>jwasham / coding-interview-university</td>\n",
       "      <td>NA</td>\n",
       "      <td>272</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>joeyballentine / chaiNNer</td>\n",
       "      <td>NA</td>\n",
       "      <td>10</td>\n",
       "      <td>[TypeScript, Python, JavaScript]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Title Description  \\\n",
       "0                            danielgindi / Charts          NA   \n",
       "1                           surrealdb / surrealdb          NA   \n",
       "2                          TheAlgorithms / Python          NA   \n",
       "3                           SerenityOS / ladybird          NA   \n",
       "4   divamgupta / diffusionbee-stable-diffusion-ui          NA   \n",
       "5                      karpathy / nn-zero-to-hero          NA   \n",
       "6        EbookFoundation / free-programming-books          NA   \n",
       "7                         twitter / compose-rules          NA   \n",
       "8                                    n8n-io / n8n          NA   \n",
       "9        InterviewReady / system-design-resources          NA   \n",
       "10                                    moby / moby          NA   \n",
       "11                          Alamofire / Alamofire          NA   \n",
       "12                     AykutSarac / jsoncrack.com          NA   \n",
       "13                        pocketbase / pocketbase          NA   \n",
       "14                              ascoders / weekly          NA   \n",
       "15                            jellyfin / jellyfin          NA   \n",
       "16                apptension / developer-handbook          NA   \n",
       "17                       vasanthk / how-web-works          NA   \n",
       "18                               rust-lang / rust          NA   \n",
       "19                                  dotnet / core          NA   \n",
       "20                         microsoft / playwright          NA   \n",
       "21                        gothinkster / realworld          NA   \n",
       "22                          SerenityOS / serenity          NA   \n",
       "23          jwasham / coding-interview-university          NA   \n",
       "24                      joeyballentine / chaiNNer          NA   \n",
       "\n",
       "   Contributors_count                                      Language_used  \n",
       "0                 150                               [Swift, Objective-C]  \n",
       "1                  11                                             [Rust]  \n",
       "2                 831                                           [Python]  \n",
       "3                  16                                 [C++, CMake, Java]  \n",
       "4                  NA                         [Jupyter Notebook, Python]  \n",
       "5                  NA                                 [Jupyter Notebook]  \n",
       "6               2,000                                               [NA]  \n",
       "7                   8                                           [Kotlin]  \n",
       "8                 301  [TypeScript, Vue, SCSS, JavaScript, HTML, Dock...  \n",
       "9                   5                                               [NA]  \n",
       "10              2,178  [Go, Shell, Dockerfile, PowerShell, Makefile, ...  \n",
       "11                240                                            [Swift]  \n",
       "12                 14                                       [TypeScript]  \n",
       "13                 14        [Go, Svelte, SCSS, JavaScript, HTML, Shell]  \n",
       "14                 67                                       [JavaScript]  \n",
       "15                758                                               [C#]  \n",
       "16                  4                                               [NA]  \n",
       "17                  8                                               [NA]  \n",
       "18              4,016  [Rust, JavaScript, HTML, Python, Makefile, Shell]  \n",
       "19                302                                [PowerShell, Shell]  \n",
       "20                294  [TypeScript, HTML, C++, CSS, JavaScript, Objec...  \n",
       "21                 73                                            [Shell]  \n",
       "22                751           [C++, JavaScript, HTML, C, Shell, CMake]  \n",
       "23                272                                               [NA]  \n",
       "24                 10                   [TypeScript, Python, JavaScript]  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Github=pd.DataFrame({'Title':Title,'Description':Description,\n",
    "                'Contributors_count':Count,'Language_used':Language})\n",
    "print('\\033[1m'+'GitHub Trending Repository :'+'\\033[0m')\n",
    "Github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e3f51c",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff1787f",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19aa9ee",
   "metadata": {},
   "source": [
    "# Q6. Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https:/www.billboard.com/ You have to find the following details:\n",
    "\n",
    "A) Song name\n",
    "\n",
    "B) Artist name\n",
    "\n",
    "C) Last week rank\n",
    "\n",
    "D) Peak rank\n",
    "\n",
    "E) Weeks on board\n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "412e995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "driver.get('https://www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "07071eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on charts\n",
    "charts=driver.find_element(By.XPATH,'//*[@id=\"main-wrapper\"]/header/div[2]/div/nav/ul/li[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8d3295a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists\n",
    "Song_Name = []\n",
    "Artist_Name = []\n",
    "Last_week_rank = []\n",
    "Peak_rank = []\n",
    "Weeks_on_board = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b3085ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping name\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]'):\n",
    "    Song_Name.append(i.text)\n",
    "len(Song_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d5a21f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrappin Artist name 1 st one\n",
    "Artist_Name.append(driver.find_element(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet']\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dc645509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remainig Artist Name\n",
    "artistTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "Artist_Name.extend([i.text for i in artistTag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a853e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scapping Rank\n",
    "rank=[]\n",
    "rankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet']\")\n",
    "rank.extend([i.text for i in rankTag[:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "86f89c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remaining RAnk\n",
    "Rank=[]\n",
    "RankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max']\")\n",
    "Rank.extend([i.text for i in RankTag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c6e2ee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing ''\n",
    "for i in Rank:\n",
    "    if i=='':\n",
    "        Rank.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ec50ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing as per requirement\n",
    "lastweekpos=Rank[0::3]\n",
    "lastweekpos.insert(0,rank[0])\n",
    "peakPos=Rank[1::3]\n",
    "peakPos.insert(0,rank[1])\n",
    "weeksonBoard=Rank[2::3]\n",
    "weeksonBoard.insert(0,rank[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7e068332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 133, 133, 133)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check length of all\n",
    "len(Song_Name),len(Artist_Name),len(lastweekpos),len(peakPos),len(weeksonBoard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7c305d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SongName</th>\n",
       "      <th>ArtistName</th>\n",
       "      <th>Last Week</th>\n",
       "      <th>PeekPosition</th>\n",
       "      <th>Weeks On board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As It Was\\nHarry Styles\\n1\\n1\\n22</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad Habit\\nSteve Lacy\\n3\\n2\\n9</td>\n",
       "      <td>Steve Lacy</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>About Damn Time\\nLizzo\\n2\\n1\\n20</td>\n",
       "      <td>Lizzo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Running Up That Hill (A Deal With God)\\nKate B...</td>\n",
       "      <td>Kate Bush</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sunroof\\nNicky Youre &amp; dazy\\n6\\n5\\n14</td>\n",
       "      <td>Nicky Youre &amp; dazy</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Thought You Should Know\\nMorgan Wallen\\n81\\n12...</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2 Be Loved (Am I Ready)\\nLizzo\\n95\\n84\\n3</td>\n",
       "      <td>Lizzo</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Wait In The Truck\\nHARDY Featuring Lainey Wils...</td>\n",
       "      <td>HARDY Featuring Lainey Wilson</td>\n",
       "      <td>68</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>La Corriente\\nBad Bunny &amp; Tony Dize\\n87\\n32\\n14</td>\n",
       "      <td>Bad Bunny &amp; Tony Dize</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bzrp Music Sessions, Vol. 52\\nBizarrap &amp; Queve...</td>\n",
       "      <td>Bizarrap &amp; Quevedo</td>\n",
       "      <td>73</td>\n",
       "      <td>63</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             SongName  \\\n",
       "0                   As It Was\\nHarry Styles\\n1\\n1\\n22   \n",
       "1                      Bad Habit\\nSteve Lacy\\n3\\n2\\n9   \n",
       "2                    About Damn Time\\nLizzo\\n2\\n1\\n20   \n",
       "3   Running Up That Hill (A Deal With God)\\nKate B...   \n",
       "4               Sunroof\\nNicky Youre & dazy\\n6\\n5\\n14   \n",
       "..                                                ...   \n",
       "95  Thought You Should Know\\nMorgan Wallen\\n81\\n12...   \n",
       "96          2 Be Loved (Am I Ready)\\nLizzo\\n95\\n84\\n3   \n",
       "97  Wait In The Truck\\nHARDY Featuring Lainey Wils...   \n",
       "98    La Corriente\\nBad Bunny & Tony Dize\\n87\\n32\\n14   \n",
       "99  Bzrp Music Sessions, Vol. 52\\nBizarrap & Queve...   \n",
       "\n",
       "                       ArtistName Last Week PeekPosition Weeks On board  \n",
       "0                    Harry Styles         1            1             22  \n",
       "1                      Steve Lacy         3            2              9  \n",
       "2                           Lizzo         2            1             20  \n",
       "3                       Kate Bush         4            3             34  \n",
       "4              Nicky Youre & dazy         6            5             14  \n",
       "..                            ...       ...          ...            ...  \n",
       "95                  Morgan Wallen        66           65             11  \n",
       "96                          Lizzo                                        \n",
       "97  HARDY Featuring Lainey Wilson        68           18             17  \n",
       "98          Bad Bunny & Tony Dize                                        \n",
       "99             Bizarrap & Quevedo        73           63             22  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "df=pd.DataFrame()\n",
    "df['SongName']=Song_Name[0:100]\n",
    "df['ArtistName']=Artist_Name\n",
    "df['Last Week']=lastweekpos[0:100]\n",
    "df[\"PeekPosition\"]=peakPos[0:100]\n",
    "df['Weeks On board']=weeksonBoard[0:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "47da1821",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4de122",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04fd064",
   "metadata": {},
   "source": [
    "# 7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/hr-recruiters-consultants You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Designation\n",
    "\n",
    "C) Company\n",
    "\n",
    "D) Skills they hire for\n",
    "\n",
    "E) Location\n",
    "\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "455f5750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let first connect to the driver\n",
    "\n",
    "driver=webdriver.Edge(r\"msedgedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92eaa6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bda31de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching urls to navigate recruiter page\n",
    "recruiter = driver.find_element(By.XPATH,'//a[@title=\"Search Jobs\"]')\n",
    "page_url = recruiter.get_attribute(\"href\")\n",
    "\n",
    "driver.get(page_url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12e6e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching search button, sending keys and clicking on it\n",
    "search = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[1]/div/div/div/input\") \n",
    "search.send_keys(\"Data science \")           \n",
    "btn = driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[6]').click()     \n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb9cad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "Name = []\n",
    "Designation = []\n",
    "Company = []\n",
    "Skills = []\n",
    "Location = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "649963b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Names\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='job-description fs12 grey-text']\"):\n",
    "    Name.append(i.text)\n",
    "time.sleep(3)\n",
    "\n",
    "#Scraping data of Designation\n",
    "for i in driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\"):\n",
    "    Designation.append(i.text)\n",
    "    \n",
    "#Scraping data of company name\n",
    "for i in driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "    Company.append(i.text)\n",
    "\n",
    "#Scraping data of locations\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='ellipsis fleft']\"):\n",
    "    Location.append(i.text)\n",
    "time.sleep(3)\n",
    "\n",
    "#Scraping data of skills\n",
    "for i in driver.find_elements(By.XPATH,\"//ul[@class='tags has-description']\"):\n",
    "    Skills.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7048bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 34 20\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(Designation),len(Company),len(Location),len(Skills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a0dcf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shift: UK ShiftShould have good communication ...</td>\n",
       "      <td>HCL Hiring For Associate Manager role into Dat...</td>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>Data Science &amp; Analytics</td>\n",
       "      <td>Power Bi\\nTableau\\nSSIS\\nForecasting\\nSQL\\ncom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please find below JD and company details TECHN...</td>\n",
       "      <td>Hiring For AVP |Data Science and Business Anal...</td>\n",
       "      <td>Citicorp Finance</td>\n",
       "      <td>Engineering - Software &amp; QA</td>\n",
       "      <td>R\\nData Science\\npython\\nBusiness Analytics\\nR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skill required: Data Science - Predictive Mode...</td>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Customer Success, Service &amp; Operations</td>\n",
       "      <td>Publishing\\nConsulting\\nPredictive modeling\\nD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ability to work under minimum supervision</td>\n",
       "      <td>Analyst, Data Science &amp; Analytics</td>\n",
       "      <td>TransUnion</td>\n",
       "      <td>Other</td>\n",
       "      <td>SQL\\ncommunication\\nIT Skills\\nData Science\\nD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Masters or PhD degree in computer science, app...</td>\n",
       "      <td>Senior Manager Data Science</td>\n",
       "      <td>Optum</td>\n",
       "      <td>WFH during Covid</td>\n",
       "      <td>Data Science\\ndeep learning\\nSQL\\nNLP\\nPython\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BTech, MTech or MCA degree from a reputed univ...</td>\n",
       "      <td>Analyst - Data Science - Python/Machine Learni...</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Python\\nData Science\\nStatistical Modeling\\nDa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Minimum 1 2 years of experience as a software ...</td>\n",
       "      <td>Data Science/ ML freshers</td>\n",
       "      <td>CliqHR Recruitment Services</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Science\\nCNN\\nKeras\\nLSTM\\nPytorch\\nPytho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Atleast 3+ years of experience in the field of...</td>\n",
       "      <td>Looking For Marketing Analytics / Campaign Ana...</td>\n",
       "      <td>Evalueserve</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>machine learning\\nab tesing\\nAttribution Model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>We are looking for exceptional individuals, wh...</td>\n",
       "      <td>Looking For Group Manager-Data Science( Retail...</td>\n",
       "      <td>Evalueserve</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>python\\ndata science\\niri\\nCART/CHAID\\ndata an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Atleast 3+ years of experience in the field of...</td>\n",
       "      <td>Looking For Campaign Analytics (Data Science) ...</td>\n",
       "      <td>Evalueserve</td>\n",
       "      <td>0-3 Lakhs</td>\n",
       "      <td>Campaign Designing\\nMedia Mix Modelling\\nmachi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Analytics Consultant/ Senior Manager- Data Sci...</td>\n",
       "      <td>Consultant/Senior Manager - Analytics/Data Sci...</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>3-6 Lakhs</td>\n",
       "      <td>Data Science\\nAnalytics\\nManagement consulting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Skill required: Data Science - Machine Learnin...</td>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-10 Lakhs</td>\n",
       "      <td>Publishing\\nArtificial Intelligence\\nConsultin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Skill required: Data Science - Predictive Mode...</td>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>10-15 Lakhs</td>\n",
       "      <td>Publishing\\nConsulting\\nPredictive modeling\\nD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bachelors degree or higher in Computer Science...</td>\n",
       "      <td>Junior Software Engineer - Data Science</td>\n",
       "      <td>LogiNext</td>\n",
       "      <td>Foreign MNC</td>\n",
       "      <td>Java\\nSaaS\\nPython\\ndata mining\\nTableau\\nC++\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Experienced candidates (and freshers) from any...</td>\n",
       "      <td>Machine Learning/Technical Analyst/Data Science</td>\n",
       "      <td>Bartleby Technologies</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>machine learning\\nIT Skills\\nData Science\\nClo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Roles and Responsibilities 1. Teaching in the ...</td>\n",
       "      <td>Data Science Trainer</td>\n",
       "      <td>STARAGILE CONSULTING</td>\n",
       "      <td>Indian MNC</td>\n",
       "      <td>trainer\\nBusiness Intelligence tools\\nData Ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Roles and Responsibilities Candidates with 8-1...</td>\n",
       "      <td>Assistant Manager/ Manager - Supply Chain Data...</td>\n",
       "      <td>Golden Opportunities</td>\n",
       "      <td>Startup</td>\n",
       "      <td>supply chain\\nBPO\\ninternational bpo\\ndata ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A work environment that encourages collaborati...</td>\n",
       "      <td>Senior Manager, Data Science And Analytics</td>\n",
       "      <td>TransUnion</td>\n",
       "      <td>Business Intelligence &amp; Analytics</td>\n",
       "      <td>IT Skills\\nJava\\nPython\\nData Science\\nMachine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Education: BE / BS/MS or equivalent in applied...</td>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>Rapido</td>\n",
       "      <td>Data Science &amp; Machine Learning</td>\n",
       "      <td>Data Science\\ndata analysis\\nNoSql\\nAgile\\ndat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>At least 2-3 years of experience of leading ju...</td>\n",
       "      <td>ACN - Applied Intelligence - CC - Data Science...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Data Science &amp; Analytics - Other</td>\n",
       "      <td>Supply chain management\\nConsulting\\nApplicati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name  \\\n",
       "0   Shift: UK ShiftShould have good communication ...   \n",
       "1   Please find below JD and company details TECHN...   \n",
       "2   Skill required: Data Science - Predictive Mode...   \n",
       "3           Ability to work under minimum supervision   \n",
       "4   Masters or PhD degree in computer science, app...   \n",
       "5   BTech, MTech or MCA degree from a reputed univ...   \n",
       "6   Minimum 1 2 years of experience as a software ...   \n",
       "7   Atleast 3+ years of experience in the field of...   \n",
       "8   We are looking for exceptional individuals, wh...   \n",
       "9   Atleast 3+ years of experience in the field of...   \n",
       "10  Analytics Consultant/ Senior Manager- Data Sci...   \n",
       "11  Skill required: Data Science - Machine Learnin...   \n",
       "12  Skill required: Data Science - Predictive Mode...   \n",
       "13  Bachelors degree or higher in Computer Science...   \n",
       "14  Experienced candidates (and freshers) from any...   \n",
       "15  Roles and Responsibilities 1. Teaching in the ...   \n",
       "16  Roles and Responsibilities Candidates with 8-1...   \n",
       "17  A work environment that encourages collaborati...   \n",
       "18  Education: BE / BS/MS or equivalent in applied...   \n",
       "19  At least 2-3 years of experience of leading ju...   \n",
       "\n",
       "                                          Designation  \\\n",
       "0   HCL Hiring For Associate Manager role into Dat...   \n",
       "1   Hiring For AVP |Data Science and Business Anal...   \n",
       "2                         Senior Analyst-Data Science   \n",
       "3                   Analyst, Data Science & Analytics   \n",
       "4                         Senior Manager Data Science   \n",
       "5   Analyst - Data Science - Python/Machine Learni...   \n",
       "6                           Data Science/ ML freshers   \n",
       "7   Looking For Marketing Analytics / Campaign Ana...   \n",
       "8   Looking For Group Manager-Data Science( Retail...   \n",
       "9   Looking For Campaign Analytics (Data Science) ...   \n",
       "10  Consultant/Senior Manager - Analytics/Data Sci...   \n",
       "11                        Senior Analyst-Data Science   \n",
       "12                        Senior Analyst-Data Science   \n",
       "13            Junior Software Engineer - Data Science   \n",
       "14    Machine Learning/Technical Analyst/Data Science   \n",
       "15                               Data Science Trainer   \n",
       "16  Assistant Manager/ Manager - Supply Chain Data...   \n",
       "17         Senior Manager, Data Science And Analytics   \n",
       "18                               Data Science Manager   \n",
       "19  ACN - Applied Intelligence - CC - Data Science...   \n",
       "\n",
       "                        Company                                Location  \\\n",
       "0              HCL Technologies                Data Science & Analytics   \n",
       "1              Citicorp Finance             Engineering - Software & QA   \n",
       "2                     Accenture  Customer Success, Service & Operations   \n",
       "3                    TransUnion                                   Other   \n",
       "4                         Optum                        WFH during Covid   \n",
       "5     Huquo Consulting Pvt. Ltd                                  Remote   \n",
       "6   CliqHR Recruitment Services                     Bangalore/Bengaluru   \n",
       "7                   Evalueserve                             Delhi / NCR   \n",
       "8                   Evalueserve                        Gurgaon/Gurugram   \n",
       "9                   Evalueserve                               0-3 Lakhs   \n",
       "10    Huquo Consulting Pvt. Ltd                               3-6 Lakhs   \n",
       "11                    Accenture                              6-10 Lakhs   \n",
       "12                    Accenture                             10-15 Lakhs   \n",
       "13                     LogiNext                             Foreign MNC   \n",
       "14        Bartleby Technologies                               Corporate   \n",
       "15         STARAGILE CONSULTING                              Indian MNC   \n",
       "16         Golden Opportunities                                 Startup   \n",
       "17                   TransUnion       Business Intelligence & Analytics   \n",
       "18                       Rapido         Data Science & Machine Learning   \n",
       "19                    Accenture        Data Science & Analytics - Other   \n",
       "\n",
       "                                               Skills  \n",
       "0   Power Bi\\nTableau\\nSSIS\\nForecasting\\nSQL\\ncom...  \n",
       "1   R\\nData Science\\npython\\nBusiness Analytics\\nR...  \n",
       "2   Publishing\\nConsulting\\nPredictive modeling\\nD...  \n",
       "3   SQL\\ncommunication\\nIT Skills\\nData Science\\nD...  \n",
       "4   Data Science\\ndeep learning\\nSQL\\nNLP\\nPython\\...  \n",
       "5   Python\\nData Science\\nStatistical Modeling\\nDa...  \n",
       "6   Data Science\\nCNN\\nKeras\\nLSTM\\nPytorch\\nPytho...  \n",
       "7   machine learning\\nab tesing\\nAttribution Model...  \n",
       "8   python\\ndata science\\niri\\nCART/CHAID\\ndata an...  \n",
       "9   Campaign Designing\\nMedia Mix Modelling\\nmachi...  \n",
       "10  Data Science\\nAnalytics\\nManagement consulting...  \n",
       "11  Publishing\\nArtificial Intelligence\\nConsultin...  \n",
       "12  Publishing\\nConsulting\\nPredictive modeling\\nD...  \n",
       "13  Java\\nSaaS\\nPython\\ndata mining\\nTableau\\nC++\\...  \n",
       "14  machine learning\\nIT Skills\\nData Science\\nClo...  \n",
       "15  trainer\\nBusiness Intelligence tools\\nData Ana...  \n",
       "16  supply chain\\nBPO\\ninternational bpo\\ndata ana...  \n",
       "17  IT Skills\\nJava\\nPython\\nData Science\\nMachine...  \n",
       "18  Data Science\\ndata analysis\\nNoSql\\nAgile\\ndat...  \n",
       "19  Supply chain management\\nConsulting\\nApplicati...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe for scraped data\n",
    "Naukri=pd.DataFrame({})\n",
    "Naukri['Name'] = Name[0:20]\n",
    "Naukri['Designation'] = Designation[0:20]\n",
    "Naukri['Company'] = Company[0:20]\n",
    "Naukri['Location'] = Location[0:20]\n",
    "Naukri['Skills']=Skills[0:20]\n",
    "Naukri\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6da28cf",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eefd663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de163b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61ec6113",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb09ce4",
   "metadata": {},
   "source": [
    "# Q8. Scrape the details of Highest selling novels.\n",
    "URL = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare \n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "843d905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get webpage\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63367c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "Bookname = []\n",
    "Authorname = []\n",
    "Volumessold = []\n",
    "Publisher = []\n",
    "Genre = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbc2629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping book names data\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody//tr/td[2]\"):\n",
    "    Bookname.append(i.text)\n",
    "    \n",
    "#Scraping author names data\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[3]\"):\n",
    "    try:\n",
    "        if i.text == '0' : raise NoSuchElementException\n",
    "        Authorname.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Authorname.append('-')\n",
    "time.sleep(1)\n",
    "\n",
    "#Scraping data of volumes sold\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[4]\"):\n",
    "    Volumessold.append(i.text)\n",
    "    \n",
    "#Scraping data of publisher names\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[5]\"):\n",
    "    Publisher.append(i.text)\n",
    "    \n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[6]\"):\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44409931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating dataframe for scraped data\n",
    "Novels=pd.DataFrame({})\n",
    "Novels['Book Name'] = Bookname\n",
    "Novels['Author'] = Authorname\n",
    "Novels['Volume sold'] = Volumessold\n",
    "Novels['Publisher'] = Publisher\n",
    "Novels['Genre'] = Genre\n",
    "Novels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c01e84",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c6beb",
   "metadata": {},
   "source": [
    "# 9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Year span\n",
    "\n",
    "C) Genre\n",
    "\n",
    "D) Run time\n",
    "\n",
    "E) Ratings\n",
    "\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "001bb435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get webpage\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02aa674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists.\n",
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []\n",
    "\n",
    "#Scraping data of Names\n",
    "for i in driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\"):\n",
    "    Name.append(i.text)\n",
    "    \n",
    "#Scraping data of Year span\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "    Year_span.append(i.text)\n",
    "    \n",
    "#Scraping data of Run time\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='runtime']\"):\n",
    "    Run_time.append(i.text)\n",
    "    \n",
    "#Scraping data of Ratings\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']//span[2]\"):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='genre']\"):\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "#Scraping data of votes\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='lister-item-content']//p[4]/span[2]\"):\n",
    "    Votes.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4c818f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,048,909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,144,963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>968,153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>288,795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>248,375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>49,552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>60,557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>194,764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>41,021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>236,388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,048,909  \n",
       "1    51 min     8.7  1,144,963  \n",
       "2    44 min     8.1    968,153  \n",
       "3    60 min     7.5    288,795  \n",
       "4    43 min     7.6    248,375  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     49,552  \n",
       "96   50 min     7.8     60,557  \n",
       "97   42 min     8.1    194,764  \n",
       "98   45 min     7.1     41,021  \n",
       "99  572 min     8.6    236,388  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe for scraped data\n",
    "TVseries=pd.DataFrame({})\n",
    "TVseries['Name'] = Name\n",
    "TVseries['Year Span'] = Year_span\n",
    "TVseries['Genre'] = Genre\n",
    "TVseries['Run Time'] = Run_time\n",
    "TVseries['Ratings'] = Ratings\n",
    "TVseries['Votes'] = Votes\n",
    "TVseries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e204abc",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77711a4",
   "metadata": {},
   "source": [
    "# 10. Details of Datasets from UCI machine learning repositories.\n",
    "\n",
    "Url = https://archive.ics.uci.edu/ You have to find the following details:\n",
    "\n",
    "A) Dataset name\n",
    "\n",
    "B) Data type\n",
    "\n",
    "C) Task\n",
    "\n",
    "D) Attribute type\n",
    "\n",
    "E) No of instances\n",
    "\n",
    "F) No of attribute\n",
    "\n",
    "G) Year\n",
    "\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7072638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get webpage\n",
    "driver.get(\" https://archive.ics.uci.edu/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2506ef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding view all dataset button from the webpage\n",
    "viewall_dataset = driver.find_element(By.XPATH,\"//tbody[1]//tr/td[2]/span[2]/a\")    \n",
    "page_url = viewall_dataset.get_attribute(\"href\")\n",
    "driver.get(page_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3c5a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching page urls of all datasets \n",
    "view_list = driver.find_element(By.XPATH,\"/html/body/table[2]/tbody/tr/td[2]/table[1]/tbody/tr/td[2]/p/a\")  \n",
    "list_url = view_list.get_attribute(\"href\")           \n",
    "driver.get(list_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd1de92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching urls for each dataset\n",
    "dataset_url = driver.find_elements(By.XPATH,\"//p[@class='normal']//b/a\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a2811f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []     \n",
    "for i in dataset_url:\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9da940e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "Dataset_name = []\n",
    "Data_type = []\n",
    "Task = []\n",
    "Attribute_type = []\n",
    "No_of_instances = []\n",
    "No_of_attributes = []\n",
    "Year = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fb244e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls[0:100]:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #Scraping Dataset name\n",
    "    try: \n",
    "        dataset_name = driver.find_element(By.XPATH,\"//span[@class='heading']\")\n",
    "        Dataset_name.append(dataset_name.text)\n",
    "    except NoSuchElementException:\n",
    "        Dataset_name.append('-')\n",
    "    \n",
    "    \n",
    "    #Scraping data type\n",
    "    try:\n",
    "        data_type = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr/td[2]\")\n",
    "        if data_type.text == \"N/A\": raise NoSuchElementException\n",
    "        Data_type.append(data_type.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_type.append('-')\n",
    "    \n",
    "    \n",
    "    #scraping Task\n",
    "    try:\n",
    "        task = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr[3]/td[2]\")\n",
    "        if task.text == \"N/A\": raise NoSuchElementException\n",
    "        Task.append(task.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append('-')\n",
    "    \n",
    "    # Scraping Attribute type\n",
    "    try:\n",
    "        attribute_type = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr[2]/td[2]\")\n",
    "        if attribute_type.text == \"N/A\": raise NoSuchElementException\n",
    "        Attribute_type.append(attribute_type.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute_type.append('-')\n",
    "    \n",
    "    \n",
    "    # Scraping No of instances\n",
    "    try:\n",
    "        instances = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr/td[4]\")\n",
    "        if instances.text == \"N/A\": raise NoSuchElementException\n",
    "        No_of_instances.append(instances.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_instances.append('-')\n",
    "    \n",
    "    \n",
    "    # Scraping No of attributes\n",
    "    try:\n",
    "        attribute = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr[2]/td[4]\")\n",
    "        if attribute.text == \"N/A\": raise NoSuchElementException\n",
    "        No_of_attributes.append(attribute.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_attributes.append('-')\n",
    "    \n",
    "    \n",
    "    # Scraping year\n",
    "    try:\n",
    "        year = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr[2]/td[6]\")\n",
    "        if year.text == \"N/A\": raise NoSuchElementException\n",
    "        Year.append(year.text[:4])\n",
    "    except NoSuchElementException:\n",
    "        Year.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd6d0860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of instance</th>\n",
       "      <th>No of attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4 GHZ Indoor Channel Measurements Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>7840</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Road Network (North Jutland, Denmark) Data Set</td>\n",
       "      <td>Sequential, Text</td>\n",
       "      <td>Regression, Clustering</td>\n",
       "      <td>Real</td>\n",
       "      <td>434874</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3W dataset Data Set</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>1984</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9mers from cullpdb Data Set</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>158716</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>: Simulated Data set of Iraqi tourism places D...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>-</td>\n",
       "      <td>232</td>\n",
       "      <td>16</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Cervical Cancer Behavior Risk Data Set</td>\n",
       "      <td>Multivariate, Univariate</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer</td>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Challenger USA Space Shuttle O-Ring Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Integer</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Character Font Images Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>745000</td>\n",
       "      <td>411</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Character Trajectories Data Set</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Real</td>\n",
       "      <td>2858</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Chemical Composition of Ceramic Samples Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Real</td>\n",
       "      <td>88</td>\n",
       "      <td>19</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Data Name  \\\n",
       "0        2.4 GHZ Indoor Channel Measurements Data Set   \n",
       "1   3D Road Network (North Jutland, Denmark) Data Set   \n",
       "2                                 3W dataset Data Set   \n",
       "3                         9mers from cullpdb Data Set   \n",
       "4   : Simulated Data set of Iraqi tourism places D...   \n",
       "..                                                ...   \n",
       "95             Cervical Cancer Behavior Risk Data Set   \n",
       "96       Challenger USA Space Shuttle O-Ring Data Set   \n",
       "97                     Character Font Images Data Set   \n",
       "98                    Character Trajectories Data Set   \n",
       "99   Chemical Composition of Ceramic Samples Data Set   \n",
       "\n",
       "                    Data Type                        Task Attribute type  \\\n",
       "0                Multivariate              Classification           Real   \n",
       "1            Sequential, Text      Regression, Clustering           Real   \n",
       "2   Multivariate, Time-Series  Classification, Clustering  Integer, Real   \n",
       "3                  Sequential  Classification, Regression           Real   \n",
       "4                Multivariate  Classification, Clustering              -   \n",
       "..                        ...                         ...            ...   \n",
       "95   Multivariate, Univariate  Classification, Clustering        Integer   \n",
       "96               Multivariate                  Regression        Integer   \n",
       "97               Multivariate              Classification  Integer, Real   \n",
       "98                Time-Series  Classification, Clustering           Real   \n",
       "99               Multivariate  Classification, Clustering           Real   \n",
       "\n",
       "   No of instance No of attributes  Year  \n",
       "0            7840                5  2018  \n",
       "1          434874                4  2013  \n",
       "2            1984                8  2019  \n",
       "3          158716                4  2021  \n",
       "4             232               16  2020  \n",
       "..            ...              ...   ...  \n",
       "95             72               19  2019  \n",
       "96             23                4  1993  \n",
       "97         745000              411  2016  \n",
       "98           2858                3  2008  \n",
       "99             88               19  2019  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe \n",
    "\n",
    "aa=pd.DataFrame({})\n",
    "aa['Data Name'] = Dataset_name[:622]\n",
    "aa['Data Type'] = Data_type[:622]\n",
    "aa['Task'] = Task[:622]\n",
    "aa['Attribute type'] = Attribute_type[:622]\n",
    "aa['No of instance'] = No_of_instances[:622]\n",
    "aa['No of attributes'] = No_of_attributes[:622]\n",
    "aa['Year'] = Year[:622]\n",
    "aa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564f85c7",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d1d1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
